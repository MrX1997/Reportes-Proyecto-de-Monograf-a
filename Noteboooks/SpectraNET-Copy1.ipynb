{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jairo Andres Saavedra Alfonso\n",
    "# 01 de Febrero de 2019\n",
    "# Universidad de Los Andes\n",
    "# Phycis \n",
    "######################__________________Weekly Report__________________######################\n",
    "# Beta 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import time\n",
    "import os\n",
    "\n",
    "cmd='jupyter nbconvert --to python SpectraNET.ipynb'\n",
    "os.system(cmd)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "\n",
    "N_sample=80000\n",
    "\n",
    "def Load_Files(file_1,file_2,N_sample,classification=True):\n",
    "    hdul = fits.open(file_1) # Open file 1 -- 'truth_DR12Q.fits'\n",
    "    info=hdul.info() # File info\n",
    "    columns=hdul[1].columns # File Columns \n",
    "    print('INFO:',info,'/n',columns)\n",
    "    data=hdul[1].data # Database of spectra with human-expert classifications \n",
    "\n",
    "    # Reading data from data_dr12.fits. This file had the spectra from data dr12. \n",
    "    hdul_2 = fits.open(file_2) # Open file 2 -- 'data_dr12.fits'\n",
    "    info2=hdul_2.info() # File info \n",
    "    columns2=hdul_2[1].columns # File Columns\n",
    "    print('INFO:',info2,'/n',columns2)\n",
    "    data2=hdul_2[1].data # Database of spectra\n",
    "    spectra=hdul_2[0].data # Spectrum of each object \n",
    "    \n",
    "    # Subset of PLATE parameters of both data\n",
    "    data_PLATE_1=data['PLATE']\n",
    "    data_PLATE_2=data2['PLATE']\n",
    "\n",
    "    # Subset of MJD parameters of both data\n",
    "    data_MJD_1=data['MJD']\n",
    "    data_MJD_2=data2['MJD']\n",
    "\n",
    "    # Subset of FIBERID parameters of both data\n",
    "    data_FIBERID_1=data['FIBERID']\n",
    "    data_FIBERID_2=data2['FIBERID']\n",
    "    data_ID_1=data['THING_ID']\n",
    "    data_ID_2=data2['TARGETID']\n",
    "    \n",
    "    # The column 'CLASS_PERSON' have a class identifier for each spectrum: STARS=1, GALAXY=4, QSO=3 and QSO_BAL=30.\n",
    "    C_P=data['CLASS_PERSON'] #Class Person column \n",
    "    STAR=C_P[C_P==1] # objects classified as stars\n",
    "    GALAXY=C_P[C_P==4] # objects classified as galaxies \n",
    "    QSO=C_P[C_P==3] # objects classified as QSO (Quasars)\n",
    "    QSO_BAL=C_P[C_P==30] # objects classified as QSO BAL (Quasars with Broad Absortions Lines)\n",
    "    N_C=C_P[C_P!=30]   \n",
    "    N_C=N_C[N_C!=3]\n",
    "    N_C=N_C[N_C!=1]\n",
    "    N_C=N_C[N_C!=4] # objects wrong classified\n",
    "    print('Star:',STAR.shape)\n",
    "    print('Galaxy:',GALAXY.shape)\n",
    "    print('QSO:',QSO.shape)\n",
    "    print('QSO BAL:',QSO_BAL.shape)\n",
    "    print('NN:',N_C.shape)\n",
    "    \n",
    "    # I create two DataFrame for Superset_DR12Q and data_dr12 with only three parameters\n",
    "    data1={'PLATE':data_PLATE_1,'MJD':data_MJD_1,'FIBERID':data_FIBERID_1,'ID':data_ID_1}\n",
    "    data1=pd.DataFrame(data=data1)\n",
    "\n",
    "    data2={'PLATE':data_PLATE_2,'MJD':data_MJD_2,'FIBERID':data_FIBERID_2,'ID':data_ID_2}\n",
    "    data2=pd.DataFrame(data=data2)\n",
    "\n",
    "    # I convert all objects in both set to string chain in orden to combine them as one new ID.\n",
    "    data1['PLATE']=data1['PLATE'].astype(str)\n",
    "    data1['MJD']=data1['MJD'].astype(str)\n",
    "    data1['FIBERID']=data1['FIBERID'].astype(str)\n",
    "    data1['PM'] = data1['MJD'].str.cat(data1['FIBERID'],sep=\"-\")\n",
    "    data1['NEWID'] = data1['PLATE'].str.cat(data1['PM'],sep=\"-\")\n",
    "    data_1=data1.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values\n",
    "\n",
    "    data2['PLATE']=data2['PLATE'].astype(str)\n",
    "    data2['MJD']=data2['MJD'].astype(str)\n",
    "    data2['FIBERID']=data2['FIBERID'].astype(str)\n",
    "    data2['PM'] = data2['MJD'].str.cat(data2['FIBERID'],sep=\"-\")\n",
    "    data2['NEWID'] = data2['PLATE'].str.cat(data2['PM'],sep=\"-\")\n",
    "    data_2=data2.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values # New set of database 2 with new ID's\n",
    "\n",
    "    # With the routine of numpy intersect1d, I find the intersections elements in both sets. This elements  \n",
    "    data_CO=np.array(np.intersect1d(data_1,data_2,return_indices=True))\n",
    "\n",
    "    data_CO_objects=data_CO[0] # The unique new ID of each element in both sets\n",
    "    data_CO_ind1=data_CO[1] # Indices of intersected elements from the original data 1 (Superset_DR12Q.fits) \n",
    "    data_CO_ind2=data_CO[2] # Indices of intersected elements form the original data 2 (data_dr12.fits)\n",
    "    print('I find',len(data_CO_objects),'objects with spectra from DR12')\n",
    "    #print(data_CO_ind1,data_CO_ind2)\n",
    "    indi={'ind1':data_CO_ind1,'ind2':data_CO_ind2}\n",
    "    ind=pd.DataFrame(data=indi,index=data_CO_ind1)\n",
    "\n",
    "    cp=np.array(data['CLASS_PERSON'],dtype=float)\n",
    "    z=np.array(data['Z_VI'],dtype=float)\n",
    "    zc=np.array(data['Z_CONF_PERSON'],dtype=float)\n",
    "    bal=np.array(data['BAL_FLAG_VI'],dtype=float)\n",
    "    bi=np.array(data['BI_CIV'],dtype=float)\n",
    "\n",
    "    d={'CLASS_PERSON':cp,'Z_VI':z,'Z_CONF_PERSON':zc,'BAL_FLAG_VI':bal,'BI_CIV':bi}\n",
    "    data_0=pd.DataFrame(data=d)#.values #super database\n",
    "    obj=data_0.loc[data_CO_ind1]\n",
    "\n",
    "    print(obj.shape)\n",
    "    # Sample of objects. I chosen 2500 object per class. \n",
    "    stars=obj.loc[obj['CLASS_PERSON']==1]\n",
    "    galaxies=obj.loc[obj['CLASS_PERSON']==4]\n",
    "    qsos=obj.loc[obj['CLASS_PERSON']==3]\n",
    "    qsos_bal=obj.loc[obj['CLASS_PERSON']==30]\n",
    "\n",
    "    sample_star=stars.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_galaxy=galaxies.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso=qsos.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso_bal=qsos_bal.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "\n",
    "    sample_objects=pd.concat([sample_star,sample_galaxy,sample_qso,sample_qso_bal])\n",
    "\n",
    "    ind_star=np.array(sample_star.index)\n",
    "    ind_galaxy=np.array(sample_galaxy.index)\n",
    "    ind_qso=np.array(sample_qso.index)\n",
    "    ind_qso_bal=np.array(sample_qso_bal.index)\n",
    "\n",
    "    indi=np.concatenate((ind_star, ind_galaxy,ind_qso,ind_qso_bal), axis=None)\n",
    "    indi1=ind.loc[indi].values\n",
    "\n",
    "    spectra_=np.zeros((N_sample,886))\n",
    "    j=0\n",
    "    for i in indi:\n",
    "        k=indi1[j,1]\n",
    "        spectra_[j,:]=spectra[k,:]#np.log(abs(spectra[k,:443]))\n",
    "        j=j+1    \n",
    "    spectra_=pd.DataFrame(spectra_)\n",
    "    X=spectra_.values\n",
    "    \n",
    "    #Renormalize spectra\n",
    "    \n",
    "    mean_flx= np.ma.average(X[:,:443], weights=X[:,443:],axis=1)\n",
    "    ll=(X[:,:443]-mean_flx.reshape(-1,1))**2\n",
    "    aveflux=np.ma.average(ll, weights=X[:,443:],axis=1)\n",
    "    sflux = np.sqrt(aveflux)\n",
    "    X = (X[:,:443]-mean_flx.reshape(-1,1))/sflux.reshape(-1,1)\n",
    "\n",
    "    \n",
    "    if(classification!=True):\n",
    "        y=sample_objects['Z_VI']\n",
    "        y=np.array(y,dtype=float)\n",
    "        return X,y\n",
    "    else:  \n",
    "        y=sample_objects['CLASS_PERSON']\n",
    "        y=y.replace([1, 4, 3, 30], [0,1,2,3]).values\n",
    "        y=np.array(y,dtype=float)\n",
    "        return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loader(X,y,N_sample,epoc=10):\n",
    "    \n",
    "    batch_size=int(N_sample/epoc)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    for i in range(y_train.shape[0]):\n",
    "        xt=X_train[i,:].reshape(1,-1)\n",
    "        train_data.append([Variable(torch.tensor(xt, dtype=torch.float)), torch.tensor(y_train[i], dtype=torch.long)])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    test_data = []\n",
    "    for i in range(y_test.shape[0]):\n",
    "        xtst=X_test[i,:].reshape(1,-1)\n",
    "        test_data.append([Variable(torch.tensor(xtst, dtype=torch.float)), torch.tensor(y_test[i], dtype=torch.long)])\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    val_data = []\n",
    "    for i in range(y_val.shape[0]):\n",
    "        xv=X_val[i,:].reshape(1,-1)\n",
    "        val_data.append([Variable(torch.tensor(xv, dtype=torch.float)), torch.tensor(y_val[i], dtype=torch.long)])\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    print('INFO')\n",
    "    print('Train shape:',y_train.shape[0])\n",
    "    print('Val shape:',y_val.shape[0])\n",
    "    print('Test shape:',y_test.shape[0])\n",
    "    return train_loader,test_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=Load_Files('truth_DR12Q.fits','data_dr12.fits',N_sample,classification=True)\n",
    "train_loader,test_loader,val_loader=Loader(X,y,N_sample,epoc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "SpectraNET",
     "Classification"
    ]
   },
   "outputs": [],
   "source": [
    "# CNN for classification\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "learning_rate=0.1\n",
    "log_interval=10\n",
    "epoc=10\n",
    "class Net_C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_C, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 100, 10,stride=2)\n",
    "        self.conv2 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv3 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv4 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.pool = nn.MaxPool1d(2, 1)\n",
    "        self.fc1 = nn.Linear(1800, 16)\n",
    "        #self.fc1 = nn.Linear(10300, 16)\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.dropout=nn.Dropout(0.25)\n",
    "        self.bn=nn.BatchNorm1d(16)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        ##x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = F.relu(self.fc1(x))     \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net_C = Net_C()\n",
    "print(net_C)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net_C.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.75, patience=8, \n",
    "                                             verbose=True, threshold=0.00001, threshold_mode='rel',\n",
    "                                             cooldown=1, min_lr=1e-8, eps=1e-08)\n",
    "\n",
    "loss_=[]\n",
    "def train(epoch):\n",
    "    #model.train()\n",
    "    scheduler.step(0)\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader,0):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net_C(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        #for _ , (data_val,target_val) in enumerate(val_loader,0)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss = loss.item()\n",
    "        loss_.append(running_loss)\n",
    "        print('Batch:',batch_idx+1,'<-->','Loss:',running_loss)\n",
    "        \n",
    "        #if(batch_idx !=0):    # print every 2000 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n",
    "            #running_loss = 0.0\n",
    "    \n",
    "\n",
    "# Training loop\n",
    "for i in range(epoc):\n",
    "    print('Epoc:',i+1)\n",
    "    train(i)\n",
    "    \n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_=np.asarray(loss_)\n",
    "\n",
    "epoch=np.linspace(0,len(loss_),len(loss_))\n",
    "\n",
    "plt.plot(epoch,loss_,label='Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Train_loss_Classification.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "d=[]\n",
    "d1=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net_C(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(predicted,predicted.shape)\n",
    "        d.append(predicted)\n",
    "        d1.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "#d=np.asarray(d)\n",
    "print(d[0].shape)\n",
    "print(d1[0].shape)\n",
    "y_pred=torch.cat((d[0],d[1]),0)\n",
    "y_test=torch.cat((d1[0],d1[1]),0)\n",
    "print(y_pred.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "class_names=['Star','Galaxy','QSO','QSO_BAL']\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,normalize=False,title=None,cmap=plt.cm.Blues):\n",
    "\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \"\"\"\n",
    "    #print(cm)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "#plt.subplots(121)\n",
    "#y_test=y_test.detach().numpy()\n",
    "#y_pred=y_pred.detach().numpy()\n",
    "#print(y_pred)\n",
    "plot_confusion_matrix(y_test, y_test, classes=class_names, title='Confusion matrix')\n",
    "plt.savefig('cm_train.png')\n",
    "#plt.subplots(122)\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, title='Confusion matrix')\n",
    "plt.savefig('cm_test.png')\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "p,r,f,s=precision_recall_fscore_support(y_test, y_pred, average=None)#,labels=['Star','Galaxy','QSO','QSO_BAL'])\n",
    "\n",
    "print('Support:','Star:',round(s[0],4),'| Galaxy:',round(s[1],4),'| QSO:',round(s[2],4),'| QSO_BAL:',round(s[3],4))\n",
    "print('Precision:','Star:',round(p[0],4),'| Galaxy:',round(p[1],4),'| QSO:',round(p[2],4),'| QSO_BAL:',round(p[3],4))\n",
    "print('Recall:','Star:',round(r[0],4),'| Galaxy:',round(r[1],4),'| QSO:',round(r[2],4),'| QSO_BAL:',round(r[3],4))\n",
    "print('F_score:','Star:',round(f[0],4),'| Galaxy:',round(f[1],4),'| QSO:',round(f[2],4),'| QSO_BAL:',round(f[3],4))\n",
    "\n",
    "end = time.time()\n",
    "print('Running time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "classes = ('Star', 'Galaxy', 'QSO', 'QSO_BAL')\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import time\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "\n",
    "N_sample=1000\n",
    "\n",
    "def Load_Files(file_1,file_2,N_sample,classification=True):\n",
    "    hdul = fits.open(file_1) # Open file 1 -- 'truth_DR12Q.fits'\n",
    "    info=hdul.info() # File info\n",
    "    columns=hdul[1].columns # File Columns \n",
    "    print('INFO:',info,'/n',columns)\n",
    "    data=hdul[1].data # Database of spectra with human-expert classifications \n",
    "\n",
    "    # Reading data from data_dr12.fits. This file had the spectra from data dr12. \n",
    "    hdul_2 = fits.open(file_2) # Open file 2 -- 'data_dr12.fits'\n",
    "    info2=hdul_2.info() # File info \n",
    "    columns2=hdul_2[1].columns # File Columns\n",
    "    print('INFO:',info2,'/n',columns2)\n",
    "    data2=hdul_2[1].data # Database of spectra\n",
    "    spectra=hdul_2[0].data # Spectrum of each object \n",
    "    \n",
    "    # Subset of PLATE parameters of both data\n",
    "    data_PLATE_1=data['PLATE']\n",
    "    data_PLATE_2=data2['PLATE']\n",
    "\n",
    "    # Subset of MJD parameters of both data\n",
    "    data_MJD_1=data['MJD']\n",
    "    data_MJD_2=data2['MJD']\n",
    "\n",
    "    # Subset of FIBERID parameters of both data\n",
    "    data_FIBERID_1=data['FIBERID']\n",
    "    data_FIBERID_2=data2['FIBERID']\n",
    "    data_ID_1=data['THING_ID']\n",
    "    data_ID_2=data2['TARGETID']\n",
    "    \n",
    "    # The column 'CLASS_PERSON' have a class identifier for each spectrum: STARS=1, GALAXY=4, QSO=3 and QSO_BAL=30.\n",
    "    C_P=data['CLASS_PERSON'] #Class Person column \n",
    "    STAR=C_P[C_P==1] # objects classified as stars\n",
    "    GALAXY=C_P[C_P==4] # objects classified as galaxies \n",
    "    QSO=C_P[C_P==3] # objects classified as QSO (Quasars)\n",
    "    QSO_BAL=C_P[C_P==30] # objects classified as QSO BAL (Quasars with Broad Absortions Lines)\n",
    "    N_C=C_P[C_P!=30]   \n",
    "    N_C=N_C[N_C!=3]\n",
    "    N_C=N_C[N_C!=1]\n",
    "    N_C=N_C[N_C!=4] # objects wrong classified\n",
    "    print('Star:',STAR.shape)\n",
    "    print('Galaxy:',GALAXY.shape)\n",
    "    print('QSO:',QSO.shape)\n",
    "    print('QSO BAL:',QSO_BAL.shape)\n",
    "    print('NN:',N_C.shape)\n",
    "    \n",
    "    # I create two DataFrame for Superset_DR12Q and data_dr12 with only three parameters\n",
    "    data1={'PLATE':data_PLATE_1,'MJD':data_MJD_1,'FIBERID':data_FIBERID_1,'ID':data_ID_1}\n",
    "    data1=pd.DataFrame(data=data1)\n",
    "\n",
    "    data2={'PLATE':data_PLATE_2,'MJD':data_MJD_2,'FIBERID':data_FIBERID_2,'ID':data_ID_2}\n",
    "    data2=pd.DataFrame(data=data2)\n",
    "\n",
    "    # I convert all objects in both set to string chain in orden to combine them as one new ID.\n",
    "    data1['PLATE']=data1['PLATE'].astype(str)\n",
    "    data1['MJD']=data1['MJD'].astype(str)\n",
    "    data1['FIBERID']=data1['FIBERID'].astype(str)\n",
    "    data1['PM'] = data1['MJD'].str.cat(data1['FIBERID'],sep=\"-\")\n",
    "    data1['NEWID'] = data1['PLATE'].str.cat(data1['PM'],sep=\"-\")\n",
    "    data_1=data1.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values\n",
    "\n",
    "    data2['PLATE']=data2['PLATE'].astype(str)\n",
    "    data2['MJD']=data2['MJD'].astype(str)\n",
    "    data2['FIBERID']=data2['FIBERID'].astype(str)\n",
    "    data2['PM'] = data2['MJD'].str.cat(data2['FIBERID'],sep=\"-\")\n",
    "    data2['NEWID'] = data2['PLATE'].str.cat(data2['PM'],sep=\"-\")\n",
    "    data_2=data2.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values # New set of database 2 with new ID's\n",
    "\n",
    "    # With the routine of numpy intersect1d, I find the intersections elements in both sets. This elements  \n",
    "    data_CO=np.array(np.intersect1d(data_1,data_2,return_indices=True))\n",
    "\n",
    "    data_CO_objects=data_CO[0] # The unique new ID of each element in both sets\n",
    "    data_CO_ind1=data_CO[1] # Indices of intersected elements from the original data 1 (Superset_DR12Q.fits) \n",
    "    data_CO_ind2=data_CO[2] # Indices of intersected elements form the original data 2 (data_dr12.fits)\n",
    "    print('I find',len(data_CO_objects),'objects with spectra from DR12')\n",
    "    #print(data_CO_ind1,data_CO_ind2)\n",
    "    indi={'ind1':data_CO_ind1,'ind2':data_CO_ind2}\n",
    "    ind=pd.DataFrame(data=indi,index=data_CO_ind1)\n",
    "\n",
    "    cp=np.array(data['CLASS_PERSON'],dtype=float)\n",
    "    z=np.array(data['Z_VI'],dtype=float)\n",
    "    zc=np.array(data['Z_CONF_PERSON'],dtype=float)\n",
    "    bal=np.array(data['BAL_FLAG_VI'],dtype=float)\n",
    "    bi=np.array(data['BI_CIV'],dtype=float)\n",
    "\n",
    "    d={'CLASS_PERSON':cp,'Z_VI':z,'Z_CONF_PERSON':zc,'BAL_FLAG_VI':bal,'BI_CIV':bi}\n",
    "    data_0=pd.DataFrame(data=d)#.values #super database\n",
    "    obj=data_0.loc[data_CO_ind1]\n",
    "\n",
    "    print(obj.shape)\n",
    "    # Sample of objects. I chosen 2500 object per class. \n",
    "    stars=obj.loc[obj['CLASS_PERSON']==1]\n",
    "    galaxies=obj.loc[obj['CLASS_PERSON']==4]\n",
    "    qsos=obj.loc[obj['CLASS_PERSON']==3]\n",
    "    qsos_bal=obj.loc[obj['CLASS_PERSON']==30]\n",
    "\n",
    "    sample_star=stars.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_galaxy=galaxies.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso=qsos.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso_bal=qsos_bal.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "\n",
    "    sample_objects=pd.concat([sample_star,sample_galaxy,sample_qso,sample_qso_bal])\n",
    "\n",
    "    ind_star=np.array(sample_star.index)\n",
    "    ind_galaxy=np.array(sample_galaxy.index)\n",
    "    ind_qso=np.array(sample_qso.index)\n",
    "    ind_qso_bal=np.array(sample_qso_bal.index)\n",
    "\n",
    "    indi=np.concatenate((ind_star, ind_galaxy,ind_qso,ind_qso_bal), axis=None)\n",
    "    indi1=ind.loc[indi].values\n",
    "\n",
    "    spectra_=np.zeros((N_sample,886))\n",
    "    j=0\n",
    "    for i in indi:\n",
    "        k=indi1[j,1]\n",
    "        spectra_[j,:]=spectra[k,:]#np.log(abs(spectra[k,:443]))\n",
    "        j=j+1    \n",
    "    spectra_=pd.DataFrame(spectra_)\n",
    "    X=spectra_.values\n",
    "    \n",
    "    #Renormalize spectra\n",
    "    \n",
    "    mean_flx= np.ma.average(X[:,:443], weights=X[:,443:],axis=1)\n",
    "    ll=(X[:,:443]-mean_flx.reshape(-1,1))**2\n",
    "    aveflux=np.ma.average(ll, weights=X[:,443:],axis=1)\n",
    "    sflux = np.sqrt(aveflux)\n",
    "    X = (X[:,:443]-mean_flx.reshape(-1,1))/sflux.reshape(-1,1)\n",
    "\n",
    "    \n",
    "    if(classification!=True):\n",
    "        y=sample_objects['Z_VI']\n",
    "        \n",
    "        y=np.array(y,dtype=float)\n",
    "        y = y.reshape(-1, 1)\n",
    "        print(y.shape)\n",
    "        y = preprocessing.normalize(y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return X,y\n",
    "    else:  \n",
    "        y=sample_objects['CLASS_PERSON']\n",
    "        y=y.replace([1, 4, 3, 30], [0,1,2,3]).values\n",
    "        y=np.array(y,dtype=float)\n",
    "        return X,y\n",
    "\n",
    "\n",
    "def Loader(X,y,N_sample,epoc=10):\n",
    "    \n",
    "    batch_size=int(N_sample/epoc)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    for i in range(y_train.shape[0]):\n",
    "        xt=X_train[i,:].reshape(1,-1)\n",
    "        train_data.append([Variable(torch.tensor(xt, dtype=torch.float)), torch.tensor(y_train[i], dtype=torch.float)])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    test_data = []\n",
    "    for i in range(y_test.shape[0]):\n",
    "        xtst=X_test[i,:].reshape(1,-1)\n",
    "        test_data.append([Variable(torch.tensor(xtst, dtype=torch.float)), torch.tensor(y_test[i], dtype=torch.float)])\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    val_data = []\n",
    "    for i in range(y_val.shape[0]):\n",
    "        xv=X_val[i,:].reshape(1,-1)\n",
    "        val_data.append([Variable(torch.tensor(xv, dtype=torch.float)), torch.tensor(y_val[i], dtype=torch.float)])\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    print('INFO')\n",
    "    print('Train shape:',y_train.shape[0])\n",
    "    print('Val shape:',y_val.shape[0])\n",
    "    print('Test shape:',y_test.shape[0])\n",
    "    return train_loader,test_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "SpectraNET",
     "Regression"
    ]
   },
   "outputs": [],
   "source": [
    "class Net_R(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_R, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 100, 10,stride=2)\n",
    "        self.conv2 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv3 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv4 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.pool = nn.MaxPool1d(2, 1)\n",
    "        self.fc1 = nn.Linear(1800, 16)\n",
    "        #self.fc1 = nn.Linear(10300, 16)\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.fc3 = nn.Linear(4, 1)\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.bn=nn.BatchNorm1d(16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        ##x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: truth_DR12Q.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       6   ()      \n",
      "  1                1 BinTableHDU     27   546856R x 9C   [J, D, J, J, J, J, J, D, D]   \n",
      "INFO: None /n ColDefs(\n",
      "    name = 'THING_ID'; format = 'J'\n",
      "    name = 'Z_VI'; format = 'D'\n",
      "    name = 'PLATE'; format = 'J'\n",
      "    name = 'MJD'; format = 'J'\n",
      "    name = 'FIBERID'; format = 'J'\n",
      "    name = 'CLASS_PERSON'; format = 'J'\n",
      "    name = 'Z_CONF_PERSON'; format = 'J'\n",
      "    name = 'BAL_FLAG_VI'; format = 'D'\n",
      "    name = 'BI_CIV'; format = 'D'\n",
      ")\n",
      "Filename: data_dr12.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       8   (886, 639464)   float64   \n",
      "  1                1 BinTableHDU     16   639464R x 4C   [J, J, J, J]   \n",
      "INFO: None /n ColDefs(\n",
      "    name = 'TARGETID'; format = 'J'\n",
      "    name = 'PLATE'; format = 'J'\n",
      "    name = 'MJD'; format = 'J'\n",
      "    name = 'FIBERID'; format = 'J'\n",
      ")\n",
      "Star: (207915,)\n",
      "Galaxy: (22795,)\n",
      "QSO: (270686,)\n",
      "QSO BAL: (29659,)\n",
      "NN: (15801,)\n",
      "I find 537677 objects with spectra from DR12\n",
      "(537677, 5)\n",
      "(1000, 1)\n",
      "INFO\n",
      "Train shape: 600\n",
      "Val shape: 200\n",
      "Test shape: 200\n"
     ]
    }
   ],
   "source": [
    "X,y=Load_Files('truth_DR12Q.fits','data_dr12.fits',N_sample,classification=False)\n",
    "train_loader,test_loader,val_loader=Loader(X,y,N_sample,epoc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_R(\n",
      "  (conv1): Conv1d(1, 100, kernel_size=(10,), stride=(2,))\n",
      "  (conv2): Conv1d(100, 100, kernel_size=(10,), stride=(2,))\n",
      "  (conv3): Conv1d(100, 100, kernel_size=(10,), stride=(2,))\n",
      "  (conv4): Conv1d(100, 100, kernel_size=(10,), stride=(2,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1800, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (fc3): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Epoc: 1\n",
      "Batch: 1 <--> Loss: 0.31498679518699646\n",
      "Batch: 2 <--> Loss: 0.23483335971832275\n",
      "Batch: 3 <--> Loss: 0.18941985070705414\n",
      "Batch: 4 <--> Loss: 0.17198555171489716\n",
      "Batch: 5 <--> Loss: 0.13019563257694244\n",
      "Batch: 6 <--> Loss: 0.15534932911396027\n",
      "Epoc: 2\n",
      "Batch: 1 <--> Loss: 0.1518455445766449\n",
      "Batch: 2 <--> Loss: 0.13133007287979126\n",
      "Batch: 3 <--> Loss: 0.1353277564048767\n",
      "Batch: 4 <--> Loss: 0.10928203910589218\n",
      "Batch: 5 <--> Loss: 0.10254823416471481\n",
      "Batch: 6 <--> Loss: 0.10849983245134354\n",
      "Epoc: 3\n",
      "Batch: 1 <--> Loss: 0.13348786532878876\n",
      "Batch: 2 <--> Loss: 0.12393444031476974\n",
      "Batch: 3 <--> Loss: 0.12785190343856812\n",
      "Batch: 4 <--> Loss: 0.0915893092751503\n",
      "Batch: 5 <--> Loss: 0.11454997956752777\n",
      "Batch: 6 <--> Loss: 0.08425227552652359\n",
      "Epoc: 4\n",
      "Batch: 1 <--> Loss: 0.09995319694280624\n",
      "Batch: 2 <--> Loss: 0.10722796618938446\n",
      "Batch: 3 <--> Loss: 0.06523960828781128\n",
      "Batch: 4 <--> Loss: 0.1020592749118805\n",
      "Batch: 5 <--> Loss: 0.09149569272994995\n",
      "Batch: 6 <--> Loss: 0.10474389046430588\n",
      "Epoc: 5\n",
      "Batch: 1 <--> Loss: 0.062408462166786194\n",
      "Batch: 2 <--> Loss: 0.11180310696363449\n",
      "Batch: 3 <--> Loss: 0.08450472354888916\n",
      "Batch: 4 <--> Loss: 0.08049879968166351\n",
      "Batch: 5 <--> Loss: 0.10168036818504333\n",
      "Batch: 6 <--> Loss: 0.04997099190950394\n",
      "Epoc: 6\n",
      "Batch: 1 <--> Loss: 0.08003898710012436\n",
      "Batch: 2 <--> Loss: 0.06453000009059906\n",
      "Batch: 3 <--> Loss: 0.04129360616207123\n",
      "Batch: 4 <--> Loss: 0.07751061022281647\n",
      "Batch: 5 <--> Loss: 0.10110440850257874\n",
      "Batch: 6 <--> Loss: 0.059361957013607025\n",
      "Epoc: 7\n",
      "Batch: 1 <--> Loss: 0.06362836062908173\n",
      "Batch: 2 <--> Loss: 0.0506550557911396\n",
      "Batch: 3 <--> Loss: 0.07754068076610565\n",
      "Batch: 4 <--> Loss: 0.08204308152198792\n",
      "Batch: 5 <--> Loss: 0.07231855392456055\n",
      "Batch: 6 <--> Loss: 0.05634110048413277\n",
      "Epoc: 8\n",
      "Batch: 1 <--> Loss: 0.0505807138979435\n",
      "Batch: 2 <--> Loss: 0.05196746066212654\n",
      "Batch: 3 <--> Loss: 0.059520844370126724\n",
      "Batch: 4 <--> Loss: 0.05737718939781189\n",
      "Batch: 5 <--> Loss: 0.05027063935995102\n",
      "Batch: 6 <--> Loss: 0.05713535100221634\n",
      "Epoc: 9\n",
      "Batch: 1 <--> Loss: 0.044247765094041824\n",
      "Batch: 2 <--> Loss: 0.062157925218343735\n",
      "Batch: 3 <--> Loss: 0.042336203157901764\n",
      "Batch: 4 <--> Loss: 0.07395841926336288\n",
      "Batch: 5 <--> Loss: 0.05041506886482239\n",
      "Batch: 6 <--> Loss: 0.044905103743076324\n",
      "Epoc: 10\n",
      "Batch: 1 <--> Loss: 0.028543369844555855\n",
      "Batch: 2 <--> Loss: 0.046689003705978394\n",
      "Batch: 3 <--> Loss: 0.03567487746477127\n",
      "Batch: 4 <--> Loss: 0.023337431252002716\n",
      "Batch: 5 <--> Loss: 0.0765216201543808\n",
      "Batch: 6 <--> Loss: 0.03026123158633709\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VPW5+PHPk50kkwSyQ4CsQNg3ERDBXait2qoVLdZ6ba292r29ta3XttbeWr1Xrbf+qrZqb1vXqm2pooiK4MqisoclhACBQBYICdmX5/fHnAmTZLKSyUKe9+s1r8ycOefM90ySeea7PV9RVYwxxpiOBPR3AYwxxgx8FiyMMcZ0yoKFMcaYTlmwMMYY0ykLFsYYYzplwcIYY0ynLFiYAU1EAkXkpIiM6e+ymFPs9zL0WLAwvcr5APHcmkSk2uvxl7p7PlVtVNVIVT3Qg7JkisiAnEgkIl8VkUbnfTkhIp+KyJL+LldXnc7vxQxOFixMr3I+QCJVNRI4AHzOa9vTrfcXkaC+L+WA8a7zPg0H/gi8ICKu3n6RIf4em15iwcL0KRG5R0SeF5FnRaQCWCYi80TkIxEpE5FCEXlYRIKd/YNEREUk1Xn8V+f510SkQkQ+FJG0HpQjzDlPoYgcEpEHRCTEeS5BRFY45TkmImu9jvuJiBwWkXIR2Ski553ue6KqTcBfgEgg0+u1zvF6XzaJyEKv5zJE5D3nPXhDRH4vIn9ynst03rObROQA8EYXzneziOQ758sTkaXO9nEistap/ZSIyDPO9ta/lxjnd1PsnOfHIiLOc18VkTUi8qDz2nkicsnpvm+mb1mwMP3h88AzQDTwPNAAfBuIA84BFgNf7+D464H/BEbgrr38sgdluAuYDUwFZjiv+2PnuR8CeUA8kOS8FiIyySnXTFWNApY4r39anG/+NwF1wEFn22hgOfAz3Nd5B/CyiMQ6hz0LvA/EAvcAy3yceiEwAbiso/OJSBTwAHCxqrqc92KLc45fAa/irv2kAI+0cxn/DwgH0oELgJuBL3s9Px/Y6pT3QeCJLrw1ZgCxYGH6w3uq+i9VbVLValXdoKrrVLVBVfOAx4FFHRz/oqpuVNV64Glgeg/K8CXg56parKpFwN3ADc5z9cBIYIyq1qnqGmd7AxAGTBKRIFXd55S3pxaISBlQDfwauF5VS5znvgwsV9WVzvv0OrAZWCwi6cA0p/x1qroW9wd6az9T1SpVre7ofM6+CkwWkTBVLVTVHV7vRSqQrKo1qvp+6xdxaoFfBO5Q1QrnPXmQU+8nwF5VfVJVG4H/A1JEJK4nb5rpHxYsTH846P1ARCaIyKsickREynF/cHf0QXLE634V7uab7koG9ns93g+Mcu7f6zx+S0T2isgPAVR1F/B9p3xFTlNaUusTi0i6V6d+WQdleE9VY3B/018BLPB6bixwndNsU+acZy7uIDYSKHWCgEeL99THtnbPp6rlwHXAbcAREXlFRMY5x30fCAY2ishWEbnRx+skAIG0/35C298Z9Oz3ZvqJBQvTH1qPUHoM2AZkOs07dwHi5zIU4v4A9RgDHAJQ1XJV/a6qpgJXAj8SkUXOc39V1XOANNwfkL9ufWJVzfPq1I/prCCqWgF8A7hZRKY6mw8CT6lqjNctQlXvd8oeKyJhXqcZ7eO83u9zR+dDVV9T1YtwB9Fc3L8TnFrGV1U1GXcwedxHH1ER0Eg776c5M1iwMAOBCzgBVIpINh33V3Sb05ntfQvA3eZ/l4jEiUg87n6Jvzr7f87pQBanXI1Ao4hki8j5IhKKu+mo2nnutKlqMfCkUw5wd3h/XkQuFvechjDntUeq6l7c7f8/E5EQEVkAXNbJS7R7PhFJdq45HHe/SaXnukTkiyLiqSGU4Q70La7ZaQ58EfgvEYl0gsl3cd5Pc2awYGEGgu8DNwIVuL/RPt/L569udVsI/AJ3m/1W3J256zhVSxgPvA2cxN2J/FtVfQ8IBe4DSnA3qwwH7uzFcj4IXC4ik1Q1H/dAgP8EinF3pH+fU/+z1znXUYq70/p5oLa9E3dyvkDcnfqFzvnmA7c7h54NbBCRSuBl4LZ25lb8O+5Asw9Yg7tf4s/dvH4zgIktfmTM4CciLwGbVLUnI8OM6ZTVLIwZhERkjoikiUiAiHwG+Czwz/4ulzlz2cxOYwankcBLuEdSFQBfU9UtHR9iTM9ZM5QxxphOWTOUMcaYTp0xzVBxcXGampra38UwxphB5eOPPy5R1fjO9jtjgkVqaiobN27s72IYY8ygIiL7O9/LmqGMMcZ0gQULY4wxnbJgYYwxplNnTJ+FMWZgqq+vp6CggJqamv4uypAWFhZGSkoKwcHBPTregoUxxq8KCgpwuVykpqbiLJ5n+piqUlpaSkFBAWlp3V5YErBmKGOMn9XU1BAbG2uBoh+JCLGxsadVu7NgYYzxOwsU/e90fwdDPliU19Tz0Ju72XywowXNjDFmaBvywUIVHnpzDxvyj/V3UYwxflBaWsr06dOZPn06SUlJjBo1qvlxXV1dl85x0003sWvXrg73eeSRR3j66ad7o8gsWLCATZs29cq5esuQ7+COCgsiJCiA4op2140xxgxisbGxzR+8P//5z4mMjOQHP/hBi31UFVUlIMD39+ennnqq09e57bbbTr+wA9iQr1mICAmuUAsWxgwxubm5TJ48mVtvvZWZM2dSWFjILbfcwuzZs5k0aRJ33313876eb/oNDQ3ExMRwxx13MG3aNObNm0dRUREAd955Jw899FDz/nfccQdz5sxh/PjxfPDBBwBUVlZy1VVXMW3aNK677jpmz57daQ3ir3/9K1OmTGHy5Mn85Cc/AaChoYEbbrihefvDDz8MwIMPPsjEiROZNm0ay5Yt69X3a8jXLADiXaEUWbAwxu9+8a/t7Dhc3qvnnDgyip99blKPjt2xYwdPPfUUjz76KAD33nsvI0aMoKGhgfPPP5+rr76aiRMntjjmxIkTLFq0iHvvvZfvfe97PPnkk9xxxx1tzq2qrF+/nuXLl3P33Xfz+uuv87//+78kJSXx0ksvsXnzZmbOnNlh+QoKCrjzzjvZuHEj0dHRXHTRRbzyyivEx8dTUlLC1q1bASgrc/e53nfffezfv5+QkJDmbb1lyNcsAOIjrWZhzFCUkZHBWWed1fz42WefZebMmcycOZOcnBx27NjR5phhw4axZMkSAGbNmkV+fr7Pc3/hC19os897773H0qVLAZg2bRqTJnUc5NatW8cFF1xAXFwcwcHBXH/99axdu5bMzEx27drFt7/9bVauXEl0dDQAkyZNYtmyZTz99NM9nnzXHqtZAAlRoWzcf7y/i2HMGa+nNQB/iYiIaL6/Z88efvvb37J+/XpiYmJYtmyZz3kJISEhzfcDAwNpaGjwee7Q0NA2+3R3sbn29o+NjWXLli289tprPPzww7z00ks8/vjjrFy5kjVr1vDPf/6Te+65h23bthEYGNit12yP1SyA+MgwjlXWUdfQ1N9FMcb0k/LyclwuF1FRURQWFrJy5cpef40FCxbwwgsvALB161afNRdvc+fOZfXq1ZSWltLQ0MBzzz3HokWLKC4uRlW55ppr+MUvfsEnn3xCY2MjBQUFXHDBBdx///0UFxdTVVXVa2X3a81CRBYDvwUCgT+q6r2tnr8VuA1oBE4Ct6jqDue5HwM3O899S1V7/zfniHe5vwGUVtaSHD3MXy9jjBnAZs6cycSJE5k8eTLp6emcc845vf4a3/zmN/nyl7/M1KlTmTlzJpMnT25uQvIlJSWFu+++m/POOw9V5XOf+xyXXXYZn3zyCTfffDOqiojwm9/8hoaGBq6//noqKipoamriRz/6ES6Xq9fK7rc1uEUkENgNXIx7QfkNwHWeYODsE6Wq5c79y4F/V9XFIjIReBaYg3th+jeBcara2N7rzZ49W3u6+NGqHUf52p83svz2c5iaEtOjcxhjfMvJySE7O7u/izEgNDQ00NDQQFhYGHv27OGSSy5hz549BAX1TY+Ar9+FiHysqrM7O9afJZwD5KpqnlOg54ArgOZg4QkUjgjAE7muAJ5T1Vpgn4jkOuf70B8FTXBqFkXl1sltjPGfkydPcuGFF9LQ0ICq8thjj/VZoDhd/izlKOCg1+MC4OzWO4nIbcD3gBDgAq9jP2p17Cgfx94C3AIwZsyYHhfU0wxVfNKChTHGf2JiYvj444/7uxg94s8Obl9Zq9q0eanqI6qaAfwIuLObxz6uqrNVdXZ8fKfrjbcrLtIJFjZ81hi/8Fdzt+m60/0d+DNYFACjvR6nAIc72P854MoeHntaQoICGB4ebMHCGD8ICwujtLTUAkY/8qxnERYW1uNz+LMZagOQJSJpwCFgKXC99w4ikqWqe5yHlwGe+8uBZ0TkAdwd3FnAej+W1ZnFbSt5GdPbUlJSKCgooLi4uL+LMqR5VsrrKb8FC1VtEJHbgZW4h84+qarbReRuYKOqLgduF5GLgHrgOHCjc+x2EXkBd2d4A3BbRyOhekO85Ycyxi+Cg4N7vDqbGTj82g2vqiuAFa223eV1/9sdHPsr4Ff+K11LCa4wNu63NOXGGOOLzeB2xLtCKSqvtXZVY4zxwYKFIz4ylNqGJipqfed5McaYocyChaN5roX1WxhjTBsWLBw2i9sYY9pnwcJhs7iNMaZ9Fiwc1gxljDHts2DhiB4WTEhggE3MM8YYHyxYOETEJuYZY0w7LFh4ibNgYYwxPlmw8JJgwcIYY3yyYOHFmqGMMcY3CxZe4iNDOVZVR31jU38XxRhjBhQLFl7iXaGowrHKuv4uijHGDCgWLLzYLG5jjPHNgoWXU7O4ba6FMcZ4s2DhxWZxG2OMbxYsvMRbM5QxxvhkwcJLaFAg0cOCLZmgMca0YsGiFZtrYYwxbVmwaMVmcRtjTFsWLFqJd4VSZMHCGGNasGDRSnyku2ahqv1dFGOMGTAsWLQS7wqlur6RyrrG/i6KMcYMGBYsWkmI8gyftYl5xhjjYcGilfjIMMAm5hljjDe/BgsRWSwiu0QkV0Tu8PH890Rkh4hsEZG3RGSs13ONIrLJuS33Zzm9nUr5YcHCGGM8gvx1YhEJBB4BLgYKgA0islxVd3jt9ikwW1WrROQbwH3Atc5z1ao63V/la48lEzTGmLb8WbOYA+Sqap6q1gHPAVd476Cqq1W1ynn4EZDix/J0SfSwYIIDxWoWxhjjxZ/BYhRw0OtxgbOtPTcDr3k9DhORjSLykYhc6esAEbnF2WdjcXHx6ZcYCAgQ4iJtYp4xxnjzWzMUID62+Zy8ICLLgNnAIq/NY1T1sIikA2+LyFZV3dviZKqPA48DzJ49u9cmRiTYxDxjjGnBnzWLAmC01+MU4HDrnUTkIuCnwOWq2vwJraqHnZ95wDvADD+WtQXLD2WMMS35M1hsALJEJE1EQoClQItRTSIyA3gMd6Ao8to+XERCnftxwDmAd8e4X1mwMMaYlvzWDKWqDSJyO7ASCASeVNXtInI3sFFVlwP3A5HA30QE4ICqXg5kA4+JSBPugHZvq1FUfhUfGcqxyloam5TAAF+tacYYM7T4s88CVV0BrGi17S6v+xe1c9wHwBR/lq0j8VFhNCmUnqwlISqsv4phjDEDhs3g9iE+0plrYU1RxhgDWLDwyWZxG2NMSxYsfPDM4i62WdzGGANYsPDJahbGGNOSBQsfwoIDiQoL4sgJS1NujDFgwaJd6fGR5Bad7O9iGGPMgGDBoh3jEiPZU1TR38UwxpgBwYJFO8Yluig5Wcexyrr+LooxxvQ7CxbtyEyIBGD3UatdGGOMBYt2jEt0AbDHgoUxxliwaE9ydBiu0CB2H7VObmOMsWDRDhEhMzHSmqGMMQYLFh0al+Bijw2fNcYYCxYdyUqM5FhlHaU2k9sYM8RZsOiAp5Pb+i2MMUOdBYsONI+Issl5xpghzoJFBxKjQnGFBVkntzFmyLNg0QERYVyiy5qhjDFDngWLToxLjGTP0QpUtb+LYowx/caCRSeyElwcr6qn5KTliDLGDF0WLDqRlejOEWVpP4wxQ5kFi06cGj5rwcIYM3RZsOhEgiuUqLAgdttMbmPMEGbBohOeEVHWDGWMGcosWHRBljN81kZEGWOGKr8GCxFZLCK7RCRXRO7w8fz3RGSHiGwRkbdEZKzXczeKyB7ndqM/y9mZcYmRnKiup7jCckQZY4YmvwULEQkEHgGWABOB60RkYqvdPgVmq+pU4EXgPufYEcDPgLOBOcDPRGS4v8ramVNpP6zfwhgzNPmzZjEHyFXVPFWtA54DrvDeQVVXq2qV8/AjIMW5fymwSlWPqepxYBWw2I9l7ZBn+KyNiDLGDFX+DBajgINejwucbe25GXitO8eKyC0islFENhYXF59mcdsXHxlKTHiwpf0wxgxZ/gwW4mObzx5iEVkGzAbu786xqvq4qs5W1dnx8fE9LmhnRMS9EJLVLIwxQ5Q/g0UBMNrrcQpwuPVOInIR8FPgclWt7c6xfSnLWWLVRkQZY4YifwaLDUCWiKSJSAiwFFjuvYOIzAAewx0oiryeWglcIiLDnY7tS5xt/WZcoovymgaKbESUMWYI8luwUNUG4HbcH/I5wAuqul1E7haRy53d7gcigb+JyCYRWe4cewz4Je6AswG429nWb7ISrJPbGDN0Bfnz5Kq6AljRattdXvcv6uDYJ4En/Ve67snyWmL13Cz/9Y8YY8xAZDO4uyguMoTh4cHWyW2MGZIsWHSRiDB5VDTv7y2hsck6uY0xQ4sFi25YetYYDh6r5u2dRZ3vbIwxZxALFt1w6aRERkaH8eR7+/q7KMYY06csWHRDUGAAX56fyod5pew4XN7fxTHGmD5jwaKblp41mmHBgTz1vtUujDFDhwWLbooJD+GqWaP45+bDlJy0CXrGmKGhS8FCRDJEJNS5f56IfEtEYvxbtIHrK/PTqGto4pl1B/q7KMYY0ye6WrN4CWgUkUzgCSANeMZvpRrgMhMiWTQunr98tJ+6hqb+Lo4xxvhdV4NFk5O+4/PAQ6r6XSDZf8Ua+P5tQRrFFbW8urVf8xsaY0yf6GqwqBeR64AbgVecbcH+KdLgsDArjsyESJ54b59lojXGnPG6GixuAuYBv1LVfSKSBvzVf8Ua+ESEm85JZduhcjbuP97fxTHGGL/qUrBQ1R2q+i1VfdZJGe5S1Xv9XLYB7wszUogeFmyT9IwxZ7yujoZ6R0SiRGQEsBl4SkQe8G/RBr5hIYFcMX0kq3cVWb4oY8wZravNUNGqWg58AXhKVWcB7aYXH0omj4qmpr6J/aWV/V0UY4zxm64GiyARSQa+yKkObgNMTI4CIKfQUpcbY85cXQ0Wd+Ne8W6vqm4QkXRgj/+KNXhkJkQSGCDkFFquKGPMmatLK+Wp6t+Av3k9zgOu8lehBpOw4EDS4yLYecSChTHmzNXVDu4UEfm7iBSJyFEReUlEUvxduMEiOznKmqGMMWe0rjZDPQUsB0YCo4B/OdsMMCHZxaGyak5U1/d3UYwxxi+6GiziVfUpVW1wbn8C4v1YrkEl2+nk3mn9FsaYM1RXg0WJiCwTkUDntgwo9WfBBpNTI6IsWBhjzkxdDRb/hnvY7BGgELgadwoQAyS4QhkeHszOI9ZvYYw5M3U13ccBVb1cVeNVNUFVr8Q9Qc/gzhPl7uRuv2ahqnxy4LilNDfGDEqns1Le93qtFGeACUlR7Dpa0W7aj9e2HeEL/+8DFt2/mj++m8fJ2oY+LqExxvTc6QQL6XQHkcUisktEckXkDh/PLxSRT0SkQUSubvVco4hscm7LT6OcfSI72UVNfRP57aT9WLn9CDHhwYyNDeeeV3OY9+u3uO/1nRRV1PRxSY0xpvtOJ1h0mDlPRAKBR4AlwETgOhGZ2Gq3A8BX8L3qXrWqTndul59GOftEdged3PWNTazeWcRF2Yk8d8s8/nnbOSzMiufRNXtZ8JvVrN93rK+La4wx3dJhsBCRChEp93GrwD3noiNzgFxVzVPVOuA54ArvHVQ1X1W3AIO+Id+T9mOnj8l5G/OPU17TwEXZCQBMGx3DI1+aydvfPw9XaJClODfGDHgdBgtVdalqlI+bS1U7SxUyCjjo9bjA2dZVYSKyUUQ+EpErfe0gIrc4+2wsLi7uxql7X1hwIBnxET5rFm/mHCUkMIBzs1pOTUmNi+CK6aN4a+dRjlfW9VVRjTGm206nGaozvvo0urPowxhVnQ1cDzwkIhltTqb6uKrOVtXZ8fH9P0fQ14goVeXNnKPMy4glIrRtfL1q1ijqG5V/bbG1vI0xA5c/g0UBMNrrcQrQ5U9EVT3s/MwD3gFm9Gbh/GFCUhSHT9RwoupU2o+9xSfZX1rFRRMTfR4zMTmKCUkuXvq4oK+KaYwx3ebPYLEByBKRNBEJAZbizi/VKREZLiKhzv044Bxgh99K2kuyk10A5HhloH0zpwiACyck+DxGRLhqZgqbC06QW2ST+owxA5PfgoWqNgC3414HIwd4QVW3i8jdInI5gIicJSIFwDXAYyKy3Tk8G9goIpuB1cC9qjrgg8VEHzmi3txxlEkjoxgZM6zd466YMZLAAOHFjw/5vYzGGNMTXVrPoqdUdQWwotW2u7zub8DdPNX6uA+AKf4smz/Eu0IZERHSnK78WGUdnxw4zu0XZHV4XIIrjIVZcfz90wJ+eOl4AgM6ncJijDF9yp/NUEOOO+2Hq7kZavXOIpoULs723V/h7apZKRwtr+X93BJ/F9MYY7rNgkUvy06KYtcRd9qPN3OOkhgVyuRRUZ0ed1F2IlFhQbz0iXV0G2MGHgsWvWxCchS1DU3sOlLB2t3FXJidiEjnzUphwYF8dtpIVm4/QkWNLaJkjBlYLFj0Ms+IqD99sI/KusbmWdtdcdXMFGrqm1ixtbDF9sNl1fx8+Xb+uck6wI0x/cOCRS/LTIgkKEB4+ZNDDAsOZH5GXJePnTkmhrS4CF5yRkWVnKzl7n/t4Lz73+FPH+TzwKrdqHZnXmP7GpuU59YfoNxqMcaYLrBg0ctCgwLJiI+koUlZkBVHWHBgl491z7kYxfr8Y/ziX9tZdN9q/vTBPq6cMZLbz89kf2kVeSW+s9p219o9xdzx8la++cyn7aZVN8YYDwsWfuBpiurKKKjWPj8zBRF46v18zhufwBvfXcR9V09j6Rz3ZPjVO4t6pYxv7jhKgMCa3cU8sGpXr5zTGHPm8us8i6FqxpjhrNh2hPPbmbXdkVExw3jyxrOId4UyeVR08/aU4eGMS4zk7Z1FfPXc9NMqnydf1aWTkogJD+aR1XuZPDKaJVOST+u8xpgzlwULP7j+7DFcPDGReFdoj45vL8icPyGBJ9/bR0VNPa6w4B6Xb9uhco6W13JRdiKfnZZMTmEFP/jbZjITIslKdLXYt6iihj9/sJ+56bEsyOp6/4sx5sxizVB+EBwY0GF6j566YHwC9Y162hP3VuW4m6DOn5BAaFAgjy6bxbCQIG75y8fNHd7HKuv49Ws5LLxvNb9bncsjq3N74xKMMYOU1SwGkVljh+MKC+LtnUUsntzzJqM3dxxl9tgRjIgIASApOozfL5vJdY9/xHee28TkkVE88d4+quobuXL6KKrqGng/t5TGJrVUJMYMUVazGESCAgNYOC6e1buKaerhCKZDZdXsKCznooktm7rOSh3BXZ+byNs7i3j47Vx35/p3FvLgtdO5eGISJ2sbyCs+2RuXYYwZhKxmMchcMD6BV7cUsv1wOVNSojs/oJW3co4C7vQird0wdyzRw4LJTIhk0shT554+2n1/08GyNn0axpihwWoWg8x54+MRgdW7ejaEdtWOo6THR5AeH9nmORHhiumjWgQKgPS4SCJDg9hScKJHr2mMGfwsWAwysZGhTEuJ4e0ezLeoqKnno7zSbs//CAgQpqZEs7mgrNuvaYw5M1iwGIQumJDA5oIySk/Wduu4tbtLqG/Udpd47cjUlBhyCsupqW/s9rHGmMHPgsUgdP74BFThnV3F3TruzZyjDA8PZuaY4d1+zemjo6lvVHK8VgE0xgwdFiwGoUkjo4h3hfJ2N/otGhqbeHtnEedPSOjR8Ndpo2MAOuy32HSwjD+szev2uY0xA58Fi0EoIEA4f3w8a3cX09DY1KVjNu4/zonq+h7lqwJIigojwRXK5oPt91s8sGo3v1qRQ0k3m8eMMQOfBYtB6oIJCVTUNPDx/uNd2v/NHUcJCQzg3HHxPXo9EWFqSgyb2unkLquq4wNnZvm6vGM9eo3+UtvQyO3PfMKuIxX9XRRjBiwLFoPUOZlxBAdKl5qiVJVVOUeZlxFLZGjPp9ZMHx1NXnGlzzUw3th+lIYmJUDgo7zSHr9Gf8gprOCVLYU8u/5AfxfFmAHLgsUg5QoLZk7aCF76+BB7jnb8jXj74XL2l1b1aBSUN0+/xVYf/Ravbi0kZfgwzs2K58NBFiw8M9PX7unegAFjhhILFoPYnZdNRASu+v0HrGvnA3rN7mKWPbGOqLAgLp10esFi6ih3sNjUqt+irKqO93NLuGxKMvMyYsktOklxRff6Lcpr6vnVqzvYX9o7izt1x14nWOQVV3LwWFWfv74xg4EFi0EsOzmKl78xnzhXKDc8sZ5Xt5xau7upSfnft/bwlafWkxQVxvLbF5DgCjut14sODyYtLqJNJ/cbO9xNUJ+Zkszc9FgA1u3reu3ieGUdX/rDOv7w7j6e23DwtMrYE3nFlUSEuFc0tNqFMb5ZsBjkRo8I5+VvzGdqSjS3PfMJf3w3jxPV9dzyl438z6rdXD5tJC//+3xS4yJ65fWmpUS3GT67wmmCmpoSzeSRUUSGBnW536Koooalj3/ErqMVjIgIYWcvzuN48eMCFvzmbarrOp5ImFdcybyMWEbFDGPtbgsWxvji12AhIotFZJeI5IrIHT6eXygin4hIg4hc3eq5G0Vkj3O70Z/lHOxiwkP461fPZsnkJO55NYdF96/mnV3F/PxzE3no2umEh/Revshpo2M4Ul7DkRM1AJyoquf93BI+MyUZESEoMICzUofz4d7Og8XhsmqufewjDh6v4k9fOYtF4+LZ2YURSZW1DZysbehwnxNV7matguPV7DzSfgBqbFIRHBKCAAAgAElEQVT2lVaSER/JwnFxvJ9bSn0XhyMbM5T4LViISCDwCLAEmAhcJyITW+12APgK8EyrY0cAPwPOBuYAPxOR7k87HkLCggP53fUz+dq5acQMC+a5W+bylXPSEOnd9Semprj7LTx5olblHKW+0d0E5TE3PZa9xZUUVdS0e579pZVc8+iHlFTU8peb5zA/M44JSS4KT9RQVlXXYRm+8fQnXPnI+1TVtR8wHnprN8er3KO2OgpAh45XU9fQRHp8BIvGxXOytoFPD3QvB9aja/byvec3deuY3vLpgeNWGzJ9wp81izlArqrmqWod8BxwhfcOqpqvqluA1l/lLgVWqeoxVT0OrAIW+7GsZ4TAAOGnl03knR+ez+zUEX55jUkjowgKELY4wWLF1kJGxQxjmle69HkZTr9FO/Mtispr+OJjH1JZ18AzX5vLrLHusmYnRwHuoaztaWxSNuYfI7foJL98ZYfPfXKLTvKXD/ez9KzRRIYGddi05enczoiPZH5mHIEBwprdXZ8ZX9/YxONr83h1a2GP1xg5HT9+eSs/fnlrn7+uGXr8GSxGAd69lQXOtl47VkRuEZGNIrKxuNi+XfWFsOBAJiS72HzwBCeq63l3TzFLJie1qMFMTI7CFRrU7hDaR9fkUXKyjme+OrfFmhwTkt1rZXSUfyq36CRVdY2MT3Tx7PqDvLa1sM0+97y6g2HBgfzg0vGMT3KR00HNwhMs0uMjiQoLZsboGNbu7vqyte/uKeZYZR21DU0Ulrdfk/KHfSWV7DxSwaGyak5Ut537Ykxv8mew8NX+0dWvXl06VlUfV9XZqjo7Pr5nM5NN901LiWFzQRmrdjhNUFNbLvEaFBjAWWkjfHZyl5ys5Zn1+7ly+igmjoxq8Vx8ZCixESEd9jF4ajQPLZ3OtJRo7nh5K4fLqpufX72riHd2FfOtC7OIiwxlQpKLnYXlqPr+09tbXMnw8ODmJWYXjYtn66ETXU5Z8vdPDzff31fct8N+X992pPl+bw4MMMYXfwaLAmC01+MU4HA7+/bmscbPpqXEUFHTwKNr9jIyOowZzmQ9b/PSY8krrqSo1bftJ97bR21DE/9+fkabY0SE7OSoDvsYthScIDI0iPGJLn67dAYNjU185/lNNDYp9Y1N3PPKDtLiIrhxfioAE5KjKK9poPCE72/9ecUnWywEtdBJh/Lens5rFxU19byx/UjzqoP7Svp22dnXt7lHoUHHtTFjeoM/g8UGIEtE0kQkBFgKLO/isSuBS0RkuNOxfYmzzQwAnpncuUUnWeKMgmrNM9/CuymqrKqOP3+Qz2VTksnwsVIfwIQkF7uOVLSbIHFLQRmTR0URECCkxkVw9xWTWb/vGP9vdS5/+XA/e4sr+elnsgkJcv9pZye5m7baq63klVSS7jWsePKoaIaHB3ep03jl9qPUNjRx66J0hgUHsq+k7yb0HSqrZnPBCa4/ewwjIkI67Ocxpjf4LVioagNwO+4P+RzgBVXdLiJ3i8jlACJylogUANcAj4nIdufYY8AvcQecDcDdzjYzAGQmRBLuTGLzHgXlbeLIKFxhQXzk1cn91Pv5VNY1cvsFme2eOzs5itqGJvJL237w1jU0kVNYwbSUUzWZL8wcxeXTRvLQW3t4YNVuzs2K48LshObnxyV5+kHafpiW19RTXFFLRsKpwBUYIJybFc/aPSWddlj/49NDjBkRzqyxw0mNi+jTmsVKpwlq8aQkspNdHTbdGdMb/DrPQlVXqOo4Vc1Q1V852+5S1eXO/Q2qmqKqEaoaq6qTvI59UlUzndtT/iyn6Z7AAGFaSky7TVCefc5OG9GchqSipp6n3t/HJRMTmZAU5fMY6LiTe+eRcuoam5qH74K76eqez08mOTqM6vpG7vrsxBY1naiwYFKGD/PZtJXn9DGkt5qwuHBcPCUna9nRQdPO0fIa3t9bwpUzRiEipMWFs6+k7/osXt92hPGJLtLjI8lOimLX0Qoa+2E0lhk6bAa36ZF7r5rCUzfNIaCDhZTmpseSV1LJ0fIa/vLRfsprGjqsVYC71hIUID6/KW92Zo5P9RpBBe6A8OzX5vKXf5tDVqKrzXETkqJ8dgDvLXKGzSa0bBJbmBUHdJz6Y/mmw6jCldNHApAWF8HB49V9MqGvuKKWDfuPsXhyEuDul6mpb+rTYGWGHgsWpkfGxkYwPqntB7M3T7/F2zuL+OO7+1g0Lr5FrcCX0KBAMuIj2emj2WjLwTJGRIQ0d+p6Gz0inPmZcT7PmZ3sIq+kss364XklJwkKEMaMCG+xPSEqjOzkqA77Lf7+6SGmjY5p7hxPi4uksUn7JBHhGzuOoApLpriDRXZyx/0yxvQGCxbGb7KTo4gKC+Le13ZyrLKOb3ZSq/CYkOzy2Qy1peAEU1Oiuz0rfUJSFI1NSm5Ryz6FvUWVjIkNJziw7b/BwnFxbMw/7jOtyK4jFewoLOfzTq0C3DULgPw+yJr7+rYjpMaGM96pRXlqYzYiyviTBQvjN4EBwpy0WE5U1zM3fUSXZ5VnJ0dx+EQNJ6pOTTSrqmtgT1EFU0dFd3CkbxOav3m3rK3klZwkPc73qKxFWfE0NGnz6n/e/rHpEIEBwmentQ0WeX6ea3Giqp4P95ayePKpUWie2piNiDL+ZMHC+NV8J/XH7edndfmYCT6Gu247VE6T0mkzli+psRGEBgW06LdobFLyS6rISPCdjXdW6nCGhwfzvRc289s39zTXMJqalOWbDnNuVhxxkaHN+w8PDyZ6WLDf+w1W5bjTwXv6Kzyyk102Mc/4lQUL41fXnz2GZ756NguyfPcn+DKxOUfUqQ8/z8ztqaO7X7MIDBDGJ7la1CwKjldR19hERjs1i9CgQP5263wWZMbx4Ju7WXjfav74bh7v5ZZwqKyaz89omX3GPSIqwu/NUK9vO0JydFiLXFzg7uQ+3IUkjD1xsraBR1bn+qxlmaGj93JXG+NDWHBgux3P7Yl3hbrXtvD6cN9ScILk6LAeL+A0IcnFWzlFqCoicmrYbHz763xkJkTy6A2z2HywjP9+Yxf3vJpDgEB4SCAX+1iiNi0uot0VC8G9Fvre4koyE3wHqM6crG1g7Z5irp8zpk2/jXcSRk8ix9Olqvxz02H+a0UORRW1RIQE8s/bF/S4/GZws5qFGXBEhAlJrjY1i9ZDZrtjQlIUpZV1FDs5n7yzzXZm2ugY/nLz2TzztbOZkzaCmxek+VwjJC0ugsMnatpdbOm1bUe46IE1XUol4ss7u4qoa2hiSasmKDg1Iqq3Orl3HC7n2sc+4jvPbyIpOozHbphFWHAgt/71407XEjFnJqtZmAEpOzmKp9ftp7FJOVnTQH5pFdfMHt35ge1o7uQurCDBFdacQHC4k0CwK+ZnxDE/o/1akqeTe/+xSp8TDz1DcX/71m7OyYzt9qiu17YdIS4yxOdAga4kYewKVeXXr+3kj+/mERMewr1fmMIXZ48mIEBwhQax7Il1/OjFLfzu+hm9vlaKGdisZmEGpAlJLmrqm9hfWsmWQ+7+imk96Nw+dT73h7fnw3Rv8cku1Sq6wxMs2ss++1FeKcOCA9mQf7xFGpSuUFXezy3hvPEJBPqYCOlJwni6I6J2Ha3g8bV5XD5tJKu/fx5L54xpnng5PzOO/1g8gVe3FvLHd/ed1uuYnvnp37fy/IYD/fLaFizMgOTdBu9Z83vKaTRDjYgIITEqtHmyX15xZYf9FT3hWec8z8eIqMIT1eSXVnH7BZkkuEJ5+K093Tr3gWNVlFXVM3NM+wtGZie72HW0/SSMXbFml7v286MlE4gOD27z/NcXprN4UhL3vr6zS0vnDnaVtQ39sqiVL41Nyt82FrB8c/8k4LZgYQakzIRIAp20H5sPlpEWF0H0sLYfXt0xISmKnCMVnKiup+Rkba/XLCJDg0hwhZLvI1h4PljPGx/P1xdl8GFeKRvyu1672HTQqV11MBpsQlIUdQ1NpzUi651dxUxIcpEc3XaWPLhrMPdfM5XU2HC++ewnzWuxn4lqGxpZeN9qfr9mb38XBXB/4ahrbGLP0b5Nhe9hwcIMSGHBgaTHRZBTWN48c/t0TUh2kVtUwe6j7tpFei8HC8DJPus7WMSEB5OdFMX1c8YQFxnSrdrF5oMnCAsOYJyP3FcentrYjh42RZ2sbWDj/mMsGtfxQmKusGAeu2EW1XWN/PDFzT16rcFga8EJSivrePmTgv4uCgD5Tgr8ooraFhNW+4oFCzNgZSdHsW7fMY6U1/RoMl6b8yVFUd+ovLnjKAAZvdwMBe4Mtj6DRV4pZ6eNICBAGBYSyNfOTefdPSV8cuB4l867paCMySOjfaYm8TjdtB8f5JZQ36gsGt/5qpOZCS6+c9E43t1Twsf7u3YNg816p+a3t7iSPUf7f3b8Pq8a456ivi+PBQszYE1IdlFR4x6m2Vs1C4BXthQSFCCMbpVAsDekxUVQWlnXYk3sg8eqKDhezbz0U/Mfls0dy/DwYP63C7WL+sYmth0+0WnADAkKIDMhssczudfsLiYiJJDZY7uWluX6s8cQEx7M79/J7dHrDXTr9x0jweWepe+9hG1/2V/iHSz6vinKgoUZsDzNKgECk0a2vwZGV6XHRRIcKBwqq243geDp8nRye/dbeNYin+s1WS4iNIivnpvO6l3FbHU68Nuz+2gFNfVNHfZXePR0RJSq8s6uYuZnxjWvMtiZiNAgbpqfxps5RWdcEsPGJuXj/ONcNDGRWWOH89oACBb5pZVkJUQyLDiwX/otLFiYASvbGe46LtHlcxJcd4UEBTR3avd257aHZyEl76aoD/NKGRERwriElv0NX543lqiwIB5+u+PaxeaD7mAyvZ2FprxlJ7s4Ul7D8crupf3YW1zJobLqTvsrWrtx/lgiQgL5/TsDoxO4t+QUllNR28Cc1BEsnpTEjsJyDvhYvbEv7SupJC0ugsyESGuGMsZbYlQoSVFhnNXFbLVd4amt9PawWY8xseGInAoWqspHe0uZmz6izUJRrrBg/m1BGqt2HO3wm/mWgjJiwoPbrLvhi2c+SevzqSrlNe13ir6zqwig28EiJjyEZXPH8sqWwz5HgQ1W6/e5+yvmpI1oTtr42rbCfiuPe62UatLiIshKiGyTbr8vWLAwA5aI8I/bzuGOJRN67ZyejLb+qlmEBgUyKmZYc7A4cKyKwydqWvRXePvK/FSCA4V/fHqo3XNuOljGtJSYLs2Ybp6f4pVXa/PBMr742IfM/uWbbDvku8lrze5iMuIjetSPc/OCNIICA3hs7eCpXXQUOAE25B8jZfgwRsYMY/SIcCaPiuL17f3XFHW4zD1sNjUugszESApP1FDRyTX0NgsWZkBLig4jIrT3stLMTh2OCEzpwboYXZXmNSLKM7+iveR+MeEhnJMZx4pthai2nfxVVdfA7qMVbbLMtifeFUpcZCg5heUcKqvmO899yhWPvM++kkoiQgP52fLtbV6nuq6RdfuOcd74hO5cZrOEqDC+ODuFFz8uGBTzLt7ccZQZd69qN3CqKuv3HWOOV412yeRkPj1QRuGJ6r4qZgv7nSawsbHhZDnNmX1du7BgYYaUWWNHsPGnFzV/A/eH9LgI8ksqUVU+zCslLjK0w5rMZyYnc/BYNdsPt22K8qzjMa0L/RUe2ckuVu04ygX//Q6vbTvCbedn8M4Pz+fHS7L5eP9x/rGpZS3mo7xS6hqaut0E5e3rCzNoUvjDu3k9PoeqsjH/GHnFJ30Gzt7y+Lt5NDYpz673nTYjr6SS0so65qSdChaXTnI3Ra3sp45uz7BZTzMU0Oed3BYszJAT67VokT+kxkVQUdtA8claPspz91d01IR08cREAgOEFVvbtolvdmZud2eeyYwxwzlRXc+SyUm8/YPz+OGlE4gMDeLqWSlMS4nm1yt2tsgc+86uIsKCA1p8OHbX6BHhXD5tJM+sO8CxbnaugztQ3LdyF1c/+iEX/M8aFt6/mjv/sZVVO45S2YtZbnMKy1m/7xiu0CCWbzrsM0Owd3+FR2ZCJFkJkf3WFJVfUklYcACJrjBGjwgnNCigzzu5LVgY08s8CQXf2VnM0fLaTteXGB4Rwrz0WFZsbdsUtbmgjFExw4h3dT3A/ft5Gbz3o/N5aOkMRsWcStsRECD8/PJJFFXU8ru3T82NWLO7mHnpsYQFB3b5NXz5xnkZVNc38qcP8rt1nKpy7+s7+f07e1l61mh+eeVkxidG8fInh/janzcy/e43+O+VuzqtbTy7/gAPrNrd4T7/90E+YcEB3H/NVCpqG3h9e9sAvX7fMeIiQ5p/jx5LJiexft8xSp00931pf2klY0dEEBAgBAYIGfGRfT7XwoKFMb3Ms673004zR3ud296WTEkiv7SqzTrhmwvKujRk1ltYcCApw313VM8YM5yrZ6XwxHt55BWfJL+kkvzSqh73V3gbl+ji0kmJPLpmL8+uP9ClpiRV5d7XdvLYmjyWzR3Df31+CjfMHcsfb5zNp3ddzDNfPZslk5P53epcfvL3bTT6SOrX1KT8ekUOP355Kw+/tYfVO4t8vlZZVR3/2HSIK6eP4tJJSYyNDeeFDW1Teazfd4w5aW1rg4snJ9Ok8IaTAaAv7SupJDXu1O80KzHSmqGMGexGxoQRHChsPlhGYlRom2+ovlwyMYkAgde8mqJKT9Zy8Fh1lybjdcd/LB5PaFAgv3xlB2ucNTZOp7/C26+/MJWz00bw45e38r0XNnfYhKSq/NeKHB5bm8eX543ll1dMbjG8ODTIvcrib5dO57bzM3h2/QG+9dyn1DWcyqpb39jED/62mcfW5vGls8eQHh/BL/61ndqGts1LL2w8SE19EzfOT0VEuGZWCh/mlbaYP3GorJpDZdU+h2tnJ7sYGxve5xP0PMNmU2NP/R1lJURyqKy6V5voOuPXYCEii0Vkl4jkisgdPp4PFZHnnefXiUiqsz1VRKpFZJNze9Sf5TSmNwUFBjTPiZiX3rVFjuJdocxJG8EKrw8iT2r23siL5S3BFcZ3Lspi9a5ifv/OXlJjw5tnnp+uEREh/OmmOXzv4nH8Y9MhrnjkfZ95lY5X1vHLV3L4w7v7+Mr8VH5x+aR23ycR4YeXTuAnn5nAq1sK+dqfN1Jd10hlbQM3/99GXv70EN+/eBz3XDmZn39uEvmlVTzxXsv1NhqblD9/uJ85aSOaBzdcNSsFEXjx44PN+23w0V/hXY7Fk5L4ILekRToXf/MeNuuR6YyI8qz42Bf8FixEJBB4BFgCTASuE5GJrXa7GTiuqpnAg8BvvJ7bq6rTndut/iqnMf6Q5jRFdWc97M9MSSa36GTzh+umg2UE+GmY75fnpZIRH8GR8ppeq1V4BAYI37owi7/efDZlVXVc/rv3eWR1Lve9vpObnlrP3P96ixm/XMWT7+/jpnNS+dnnJnYpoN6yMIN7vzCFtXuKueGJdVz/h494b08x935hCt+8MAsRYeG4eC6ZmMjv3s5tMYz37Z1FFByv5ivzU5u3JUcPY2FWPH/7uKC5eWvdvmO4woJ8rnQIsHhyEg1Nyls5fdcU5Uk536Jmkdj3I6L8WbOYA+Sqap6q1gHPAVe02ucK4P+c+y8CF4qt1WjOAJ4Z4nO70F/hcemkJERobubYUlBGVoKrV+eZeIQEBfDzyycRIHCpjzW9e8M5mXGs+Na5TE2J5v6Vu/jDu3kUnqhhXkYsP/nMBJ792lzu+mzXAoXH0jlj+N11M9lcUMbOIxU8dsNsls4Z02Kf//zsRBqb3E1cHv/3QT5JUWFcPDGxxb7XnjWawhM1vJfrXhd9/b5SZo8d7nM1QnCnXBkVM4z7V+7q1nokpyPfaSbz7rMYOyKc4EDp005uf67BPQo46PW4ADi7vX1UtUFETgCe/640EfkUKAfuVNV3W7+AiNwC3AIwZsyY1k8b02+umzOGxKiwLqXo8EiMCmP22OGs2FrINy/IZHPBCS7KPv2O5/acmxXPp3ddctqLSnUkISqMZ742l4LjVSRHD+tyksKOXDY1mTEjwgkJCmB8Utv1PUaPCOfrizJ4+K09XH+2e+2Q93JL+MEl49okj7wwO4Hh4cG8sPEgk0ZGsbe4kqtntb/Wu4jw6LJZ3P7sJ1z72Id868Isbj8/kyA/JKX08B426xEUGEB6XGSfpk73Z83CV2huPZShvX0KgTGqOgP4HvCMiLSpF6rq46o6W1Vnx8f3blXamNORFhfBzQvSuvWtGdwzhXceqWDtnhKOVdZ1azJeT/gzUHgEBghjYyN6JVB4TEmJ9hkoPL6xKINRMcP4+fLtPPl+PiGBAW1qIODuRL9yxihWbT/avM7JnLT2l671vPYr31zAFdNH8dCbe7juDx9xqKxrM7uPltfw3yt3datjOr+kktTYiDa5xTIT+3b4rD+DRQHgHaJTgNaLxzbvIyJBQDRwTFVrVbUUQFU/BvYC4/xYVmMGBE/Sut+8thOAab3cuT1UDAsJ5M7Lstl5pIJn1h3gs9OSiWtnMuYXZ4+mrrGJ+1buIjQogCmjOn/PXWHBPHjtdB68dho7Dpez5KG1zcGmIw+/tYffrc7lV15NZJ3JL61kbGzbGmpWQiQHj1f5nFjoD/4MFhuALBFJE5EQYCmwvNU+y4EbnftXA2+rqopIvNNBjoikA1lAz/MIGDNIjIwZxvTRMewoLCe0nWYW0zWLJyexIDMOgBvnpba7X3ZyFFNTojlWWcfMMcO7VQP6/IwUXv3WuaQMD+e7z2/qMEFheU09f//0ENHDgnlm3YF254N4ax4262O02rhEF6p9NyLKb8FCVRuA24GVQA7wgqpuF5G7ReRyZ7cngFgRycXd3OQZXrsQ2CIim3F3fN+qqn3Tm2RMP/vMFHftYtLIKL8s0DRUiAj/88VpPHTt9E6b866Z7W4EOasHKU9S4yK472r3jPCnP/KdbwrgpY8LqKpr5MmvzGZ8oov/eGlLp+uOeIbNpsW2DRaeHFF9lVDQr3+JqrpCVcepaoaq/srZdpeqLnfu16jqNaqaqapzVDXP2f6Sqk5S1WmqOlNV/+XPchozkCyZnAx0L3mg8S0xKowrZ4zqdL8rp49kyeQkrpw+skevM3lUNAsy43jy/X3U1LdtFmpqUv7y4X5mjIlh1tgRPHjtdMqq6rjzH9s6nOnuGTY71kewGBsbQVCA9FmOKPvaYswAM3pEOI8um8nXF2b0d1GGDFdYML9fNov001jn5BvnZVBcUcvffaxN8v7eEvJKKvnyvLEATBwZxXcvHserWwv556bWXbmneBaU8pUFICQogNS4iD6ba2HBwpgBaPHkZJKiwzrf0QwY8zNimTIqmsfX5rXJYfXnD/cTGxHCZ6YkN2/7+sIMZo0dzn/+cxuH2xlNlV9a5R42G+W7c74vV82zYGGMMb1ARLh1UQb7Sip5wyuVecHxKt7KOcrSOaMJDTqV2TcwQHjgi9NobFJ++OJmmnwkSfQMm21vCHZWQiT5pZU+c2H1NgsWxhjTSxZPTiI1NpxH1+xt7ot4ep270/v6s8e22X9sbAR3XjaR93NLeXZD287xfaWVLdJ8tJaZ6KJJIa/Y/+ufW7AwxpheEhggfG1hOpsLTvDh3lJq6ht5fsNBLspObLG2iLfr5oxmbvoIfvPaToorTq2V4R42W8XYuPazADSvmtcHTVEWLIwxphddNTOFuMhQfr9mL69uKeRYZR03eiUwbE1EuOfKKVTXN7bIZ3W4rJr6RvU5bNYjPT6CAIHcPkj7YcHCGGN6UVhwIP+2IJV395TwwKrdZMRHML+T7MOZCZHcuiiDv396iA/2upMaNmeb7SB9fGhQIKmxEVazMMaYwehLZ48lMjSIQ2XVfHleapdyhN12fiZjRoRz5z+2UdvQ2DxstqM+C3AHmpI+WOrVgoUxxvSy6GHB3HROKsPDg/nCzM4nBYK7RnL3FZPIK67k8TV57CupYlhwYLvDZj1+d/1M/nbr/N4odof8maLcGGOGrO9eNI5bF2V0az2S88YncNnUZP53dS7pcRGMjQ3vtFbSm9l8O2I1C2OM8YOAAOnRwlV3fXYiIYEB7DxS0WkTVF+yYGGMMQNIYlQYP7jEvSJDb62N3husGcoYYwaYG+alUnyyliumd62/oy9YsDDGmAEmMED44aUT+rsYLVgzlDHGmE5ZsDDGGNMpCxbGGGM6ZcHCGGNMpyxYGGOM6ZQFC2OMMZ2yYGGMMaZTFiyMMcZ0SjxL/w12IlIM7D+NU8QBJb1UnP50plwH2LUMVGfKtZwp1wGndy1jVTW+s53OmGBxukRko6rO7u9ynK4z5TrArmWgOlOu5Uy5Duiba7FmKGOMMZ2yYGGMMaZTFixOeby/C9BLzpTrALuWgepMuZYz5TqgD67F+iyMMcZ0ymoWxhhjOmXBwhhjTKeGfLAQkcUisktEckXkjv4uT3eIyJMiUiQi27y2jRCRVSKyx/k5vD/L2FUiMlpEVotIjohsF5FvO9sH1fWISJiIrBeRzc51/MLZniYi65zreF5EQvq7rF0lIoEi8qmIvOI8HpTXIiL5IrJVRDaJyEZn26D6+wIQkRgReVFEdjr/L/P64jqGdLAQkUDgEWAJMBG4TkQm9m+puuVPwOJW2+4A3lLVLOAt5/Fg0AB8X1WzgbnAbc7vYrBdTy1wgapOA6YDi0VkLvAb4EHnOo4DN/djGbvr20CO1+PBfC3nq+p0rzkJg+3vC+C3wOuqOgGYhvt34//rUNUhewPmASu9Hv8Y+HF/l6ub15AKbPN6vAtIdu4nA7v6u4w9vK5/AhcP5usBwoFPgLNxz64Ncra3+LsbyDcgxfnwuQB4BZBBfC35QFyrbYPq7wuIAvbhDE7qy+sY0jULYBRw0OtxgbNtMEtU1UIA52dCP5en20QkFZgBrGMQXo/TbLMJKAJWAXuBMlVtcHYZTH9nDwH/ATQ5j2MZvNeiwBsi8rGI3CR4RiMAAAOISURBVOJsG2x/X+lAMfCU0zT4RxGJoA+uY6gHC/GxzcYS9yMRiQReAr6jquX9XZ6eUNVGVZ2O+1v5HCDb1259W6ruE5HPAkWq+rH3Zh+7DvhrcZyjqjNxNzvfJiIL+7tAPRAEzAR+r6ozgEr6qOlsqAeLAmC01+MU4HA/laW3HBWRZADnZ1E/l6fLRCQYd6B4WlVfdjYP2utR1TLgHdx9MDEiEuQ8NVj+zs4BLheRfOA53E1RDzE4rwVVPez8LAL+jjuQD7a/rwKgQFXXOY9fxB08/H4dQz1YbACynNEdIcBSYHk/l+l0LQdudO7fiLvtf8ATEQGeAHJU9QGvpwbV9YhIvIjEOPeHARfh7oBcDVzt7DbgrwNAVX+sqimqmor7f+NtVf0Sg/BaRCRCRFye+8AlwDYG2d+Xqh4BDorIeGfThcAO+uI6+rvDpr9vwGeA3bjblX/a3+XpZtmfBQqBetzfOG7G3ab8FrDH+Tmiv8vZxWtZgLs5Ywuwybl9ZrBdDzAV+NS5jm3AXc72dGA9kAv8DQjt77J287rOA14ZrNfilHmzc9vu+V8fbH9fTpmnAxudv7F/AMP74jos3YcxxphODfVmKGOMMV1gwcIYY0ynLFgYY4zplAULY4wxnbJgYYwxplMWLIzpBhFpdLKWem69NntWRFK9MwgbM5AEdb6LMcZLtbpTeRgzpFjNwphe4KyV8BtnLYv1IpLpbB8rIm+JyBbn5xhne6KI/N1Z92KziMx3ThUoIn9w1sJ4w5kFbky/s2BhTPcMa9UMda3Xc+WqOgf4He4cSjj3/6yqU4GngYed7Q8Da9S97sVM3LOKAbKAR1R1ElAGXOXn6zGmS2wGtzHdICInVTXSx/Z83Ise5TkJEY+oaqyIlOBeZ6De2V6oqnEiUgykqGqt1zlSgVXqXsAGEfkREKyq9/j/yozpmNUsjOk92s799vbxpdbrfiPWr2gGCAsWxvSea71+fujc/wB3xlbg/7d3hzgKxkAYQL9RBLOn4TIERVCYXcVlEJwDg8NwF+5QxF/WNmxgQbynmlF1M9M2naySnPv6lGSb/A5L+vqvTcJfqFrgMfM+Be/u2Fq7P5+dVdUlUxG27LHvJIeq2mWacLbu8Z8k+6raZOogtpl+EIaP5M4CnqDfWSxaa9d37wVewTEUAEM6CwCGdBYADEkWAAxJFgAMSRYADEkWAAzdAFKtuxSbK0AEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "learning_rate=0.01\n",
    "log_interval=10\n",
    "epoc=10\n",
    "\n",
    "net_R = Net_R()\n",
    "print(net_R)\n",
    "\n",
    "optimizer = torch.optim.SGD(net_R.parameters(), lr=0.2) #for Rgrss\n",
    "loss_func = torch.nn.MSELoss()  \n",
    "loss_=[]\n",
    "def train(epoch):\n",
    "    #model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader,0):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net_R(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss = loss.item()\n",
    "        loss_.append(running_loss)\n",
    "        print('Batch:',batch_idx+1,'<-->','Loss:',running_loss)\n",
    "        #if(batch_idx !=0):    # print every 2000 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n",
    "            #running_loss = 0.0\n",
    "    \n",
    "\n",
    "\n",
    "# Training loop\n",
    "for i in range(epoc):\n",
    "    print('Epoc:',i+1)\n",
    "    train(i)\n",
    "    \n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "loss_=np.asarray(loss_)\n",
    "\n",
    "epoch=np.linspace(0,len(loss_),len(loss_))\n",
    "\n",
    "plt.plot(epoch,loss_,label='Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss - Regression')\n",
    "plt.legend()\n",
    "plt.savefig('Train_loss_Regression.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "d=[]\n",
    "d1=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net_R(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(predicted,predicted.shape)\n",
    "        d.append(predicted)\n",
    "        d1.append(labels)\n",
    "        #total += labels.size(0)\n",
    "        #correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "#print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "#d=np.asarray(d)\n",
    "print(d[0].shape)\n",
    "print(d1[0].shape)\n",
    "y_pred=torch.cat((d[0],d[1]),0)\n",
    "y_test=torch.cat((d1[0],d1[1]),0)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]) tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8402eb1780>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(y_pred,y_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_pred, y_test)\n",
    "plt.scatter(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
