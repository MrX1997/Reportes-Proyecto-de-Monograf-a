{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jairo Andres Saavedra Alfonso\n",
    "# 01 de Febrero de 2019\n",
    "# Universidad de Los Andes\n",
    "# Phycis \n",
    "######################__________________Weekly Report__________________######################\n",
    "# Beta 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook SpectraNET.ipynb to python\n",
      "[NbConvertApp] Writing 25493 bytes to SpectraNET.py\n"
     ]
    }
   ],
   "source": [
    "#Packages\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import time\n",
    "\n",
    "!jupyter nbconvert --to python SpectraNET.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "\n",
    "N_sample=60000\n",
    "\n",
    "def Load_Files(file_1,file_2,N_sample,classification=True):\n",
    "    hdul = fits.open(file_1) # Open file 1 -- 'truth_DR12Q.fits'\n",
    "    info=hdul.info() # File info\n",
    "    columns=hdul[1].columns # File Columns \n",
    "    print('INFO:',info,'/n',columns)\n",
    "    data=hdul[1].data # Database of spectra with human-expert classifications \n",
    "\n",
    "    # Reading data from data_dr12.fits. This file had the spectra from data dr12. \n",
    "    hdul_2 = fits.open(file_2) # Open file 2 -- 'data_dr12.fits'\n",
    "    info2=hdul_2.info() # File info \n",
    "    columns2=hdul_2[1].columns # File Columns\n",
    "    print('INFO:',info2,'/n',columns2)\n",
    "    data2=hdul_2[1].data # Database of spectra\n",
    "    spectra=hdul_2[0].data # Spectrum of each object \n",
    "    \n",
    "    # Subset of PLATE parameters of both data\n",
    "    data_PLATE_1=data['PLATE']\n",
    "    data_PLATE_2=data2['PLATE']\n",
    "\n",
    "    # Subset of MJD parameters of both data\n",
    "    data_MJD_1=data['MJD']\n",
    "    data_MJD_2=data2['MJD']\n",
    "\n",
    "    # Subset of FIBERID parameters of both data\n",
    "    data_FIBERID_1=data['FIBERID']\n",
    "    data_FIBERID_2=data2['FIBERID']\n",
    "    data_ID_1=data['THING_ID']\n",
    "    data_ID_2=data2['TARGETID']\n",
    "    \n",
    "    # The column 'CLASS_PERSON' have a class identifier for each spectrum: STARS=1, GALAXY=4, QSO=3 and QSO_BAL=30.\n",
    "    C_P=data['CLASS_PERSON'] #Class Person column \n",
    "    STAR=C_P[C_P==1] # objects classified as stars\n",
    "    GALAXY=C_P[C_P==4] # objects classified as galaxies \n",
    "    QSO=C_P[C_P==3] # objects classified as QSO (Quasars)\n",
    "    QSO_BAL=C_P[C_P==30] # objects classified as QSO BAL (Quasars with Broad Absortions Lines)\n",
    "    N_C=C_P[C_P!=30]   \n",
    "    N_C=N_C[N_C!=3]\n",
    "    N_C=N_C[N_C!=1]\n",
    "    N_C=N_C[N_C!=4] # objects wrong classified\n",
    "    print('Star:',STAR.shape)\n",
    "    print('Galaxy:',GALAXY.shape)\n",
    "    print('QSO:',QSO.shape)\n",
    "    print('QSO BAL:',QSO_BAL.shape)\n",
    "    print('NN:',N_C.shape)\n",
    "    \n",
    "    # I create two DataFrame for Superset_DR12Q and data_dr12 with only three parameters\n",
    "    data1={'PLATE':data_PLATE_1,'MJD':data_MJD_1,'FIBERID':data_FIBERID_1,'ID':data_ID_1}\n",
    "    data1=pd.DataFrame(data=data1)\n",
    "\n",
    "    data2={'PLATE':data_PLATE_2,'MJD':data_MJD_2,'FIBERID':data_FIBERID_2,'ID':data_ID_2}\n",
    "    data2=pd.DataFrame(data=data2)\n",
    "\n",
    "    # I convert all objects in both set to string chain in orden to combine them as one new ID.\n",
    "    data1['PLATE']=data1['PLATE'].astype(str)\n",
    "    data1['MJD']=data1['MJD'].astype(str)\n",
    "    data1['FIBERID']=data1['FIBERID'].astype(str)\n",
    "    data1['PM'] = data1['MJD'].str.cat(data1['FIBERID'],sep=\"-\")\n",
    "    data1['NEWID'] = data1['PLATE'].str.cat(data1['PM'],sep=\"-\")\n",
    "    data_1=data1.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values\n",
    "\n",
    "    data2['PLATE']=data2['PLATE'].astype(str)\n",
    "    data2['MJD']=data2['MJD'].astype(str)\n",
    "    data2['FIBERID']=data2['FIBERID'].astype(str)\n",
    "    data2['PM'] = data2['MJD'].str.cat(data2['FIBERID'],sep=\"-\")\n",
    "    data2['NEWID'] = data2['PLATE'].str.cat(data2['PM'],sep=\"-\")\n",
    "    data_2=data2.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values # New set of database 2 with new ID's\n",
    "\n",
    "    # With the routine of numpy intersect1d, I find the intersections elements in both sets. This elements  \n",
    "    data_CO=np.array(np.intersect1d(data_1,data_2,return_indices=True))\n",
    "\n",
    "    data_CO_objects=data_CO[0] # The unique new ID of each element in both sets\n",
    "    data_CO_ind1=data_CO[1] # Indices of intersected elements from the original data 1 (Superset_DR12Q.fits) \n",
    "    data_CO_ind2=data_CO[2] # Indices of intersected elements form the original data 2 (data_dr12.fits)\n",
    "    print('I find',len(data_CO_objects),'objects with spectra from DR12')\n",
    "    #print(data_CO_ind1,data_CO_ind2)\n",
    "    indi={'ind1':data_CO_ind1,'ind2':data_CO_ind2}\n",
    "    ind=pd.DataFrame(data=indi,index=data_CO_ind1)\n",
    "\n",
    "    cp=np.array(data['CLASS_PERSON'],dtype=float)\n",
    "    z=np.array(data['Z_VI'],dtype=float)\n",
    "    zc=np.array(data['Z_CONF_PERSON'],dtype=float)\n",
    "    bal=np.array(data['BAL_FLAG_VI'],dtype=float)\n",
    "    bi=np.array(data['BI_CIV'],dtype=float)\n",
    "\n",
    "    d={'CLASS_PERSON':cp,'Z_VI':z,'Z_CONF_PERSON':zc,'BAL_FLAG_VI':bal,'BI_CIV':bi}\n",
    "    data_0=pd.DataFrame(data=d)#.values #super database\n",
    "    obj=data_0.loc[data_CO_ind1]\n",
    "\n",
    "    print(obj.shape)\n",
    "    # Sample of objects. I chosen 2500 object per class. \n",
    "    stars=obj.loc[obj['CLASS_PERSON']==1]\n",
    "    galaxies=obj.loc[obj['CLASS_PERSON']==4]\n",
    "    qsos=obj.loc[obj['CLASS_PERSON']==3]\n",
    "    qsos_bal=obj.loc[obj['CLASS_PERSON']==30]\n",
    "\n",
    "    sample_star=stars.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_galaxy=galaxies.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso=qsos.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso_bal=qsos_bal.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "\n",
    "    sample_objects=pd.concat([sample_star,sample_galaxy,sample_qso,sample_qso_bal])\n",
    "\n",
    "    ind_star=np.array(sample_star.index)\n",
    "    ind_galaxy=np.array(sample_galaxy.index)\n",
    "    ind_qso=np.array(sample_qso.index)\n",
    "    ind_qso_bal=np.array(sample_qso_bal.index)\n",
    "\n",
    "    indi=np.concatenate((ind_star, ind_galaxy,ind_qso,ind_qso_bal), axis=None)\n",
    "    indi1=ind.loc[indi].values\n",
    "\n",
    "    spectra_=np.zeros((N_sample,886))\n",
    "    j=0\n",
    "    for i in indi:\n",
    "        k=indi1[j,1]\n",
    "        spectra_[j,:]=spectra[k,:]#np.log(abs(spectra[k,:443]))\n",
    "        j=j+1    \n",
    "    spectra_=pd.DataFrame(spectra_)\n",
    "    X=spectra_.values\n",
    "    \n",
    "    #Renormalize spectra\n",
    "    \n",
    "    mean_flx= np.ma.average(X[:,:443], weights=X[:,443:],axis=1)\n",
    "    ll=(X[:,:443]-mean_flx.reshape(-1,1))**2\n",
    "    aveflux=np.ma.average(ll, weights=X[:,443:],axis=1)\n",
    "    sflux = np.sqrt(aveflux)\n",
    "    X = (X[:,:443]-mean_flx.reshape(-1,1))/sflux.reshape(-1,1)\n",
    "\n",
    "    \n",
    "    if(classification!=True):\n",
    "        y=sample_objects['Z_VI']\n",
    "        y=np.array(y,dtype=float)\n",
    "        return X,y\n",
    "    else:  \n",
    "        y=sample_objects['CLASS_PERSON']\n",
    "        y=y.replace([1, 4, 3, 30], [0,1,2,3]).values\n",
    "        y=np.array(y,dtype=float)\n",
    "        return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loader(X,y,N_sample,epoc=10):\n",
    "    \n",
    "    batch_size=int(N_sample/epoc)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    for i in range(y_train.shape[0]):\n",
    "        xt=X_train[i,:].reshape(1,-1)\n",
    "        train_data.append([Variable(torch.tensor(xt, dtype=torch.float)), torch.tensor(y_train[i], dtype=torch.long)])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    test_data = []\n",
    "    for i in range(y_test.shape[0]):\n",
    "        xtst=X_test[i,:].reshape(1,-1)\n",
    "        test_data.append([Variable(torch.tensor(xtst, dtype=torch.float)), torch.tensor(y_test[i], dtype=torch.long)])\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    val_data = []\n",
    "    for i in range(y_val.shape[0]):\n",
    "        xv=X_val[i,:].reshape(1,-1)\n",
    "        val_data.append([Variable(torch.tensor(xv, dtype=torch.float)), torch.tensor(y_val[i], dtype=torch.long)])\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    print('INFO')\n",
    "    print('Train shape:',y_train.shape[0])\n",
    "    print('Val shape:',y_val.shape[0])\n",
    "    print('Test shape:',y_test.shape[0])\n",
    "    return train_loader,test_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: truth_DR12Q.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       6   ()      \n",
      "  1                1 BinTableHDU     27   546856R x 9C   [J, D, J, J, J, J, J, D, D]   \n",
      "INFO: None /n ColDefs(\n",
      "    name = 'THING_ID'; format = 'J'\n",
      "    name = 'Z_VI'; format = 'D'\n",
      "    name = 'PLATE'; format = 'J'\n",
      "    name = 'MJD'; format = 'J'\n",
      "    name = 'FIBERID'; format = 'J'\n",
      "    name = 'CLASS_PERSON'; format = 'J'\n",
      "    name = 'Z_CONF_PERSON'; format = 'J'\n",
      "    name = 'BAL_FLAG_VI'; format = 'D'\n",
      "    name = 'BI_CIV'; format = 'D'\n",
      ")\n",
      "Filename: data_dr12.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       8   (886, 639464)   float64   \n",
      "  1                1 BinTableHDU     16   639464R x 4C   [J, J, J, J]   \n",
      "INFO: None /n ColDefs(\n",
      "    name = 'TARGETID'; format = 'J'\n",
      "    name = 'PLATE'; format = 'J'\n",
      "    name = 'MJD'; format = 'J'\n",
      "    name = 'FIBERID'; format = 'J'\n",
      ")\n",
      "Star: (207915,)\n",
      "Galaxy: (22795,)\n",
      "QSO: (270686,)\n",
      "QSO BAL: (29659,)\n",
      "NN: (15801,)\n",
      "I find 537677 objects with spectra from DR12\n",
      "(537677, 5)\n",
      "INFO\n",
      "Train shape: 36000\n",
      "Val shape: 12000\n",
      "Test shape: 12000\n"
     ]
    }
   ],
   "source": [
    "X,y=Load_Files('truth_DR12Q.fits','data_dr12.fits',N_sample,classification=True)\n",
    "train_loader,test_loader,val_loader=Loader(X,y,N_sample,epoc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": [
     "SpectraNET",
     "Classification"
    ]
   },
   "outputs": [],
   "source": [
    "# CNN for classification\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "learning_rate=0.01\n",
    "log_interval=10\n",
    "epoc=10\n",
    "class Net_C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_C, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 100, 10,stride=2)\n",
    "        self.conv2 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv3 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv4 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.pool = nn.MaxPool1d(2, 1)\n",
    "        self.fc1 = nn.Linear(1800, 16)\n",
    "        #self.fc1 = nn.Linear(10300, 16)\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        ##x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = F.relu(self.fc1(x))     \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_C(\n",
      "  (conv1): Conv1d(1, 100, kernel_size=(10,), stride=(2,))\n",
      "  (conv2): Conv1d(100, 100, kernel_size=(10,), stride=(2,))\n",
      "  (conv3): Conv1d(100, 100, kernel_size=(10,), stride=(2,))\n",
      "  (conv4): Conv1d(100, 100, kernel_size=(10,), stride=(2,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1800, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      ")\n",
      "Epoc: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steingate/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 <--> Loss: 1.3896160125732422\n",
      "Batch: 2 <--> Loss: 1.3715596199035645\n",
      "Batch: 3 <--> Loss: 1.322806715965271\n",
      "Batch: 4 <--> Loss: 1.235684871673584\n",
      "Batch: 5 <--> Loss: 1.159921646118164\n",
      "Batch: 6 <--> Loss: 1.2337300777435303\n",
      "Epoc: 2\n",
      "Batch: 1 <--> Loss: 1.0997968912124634\n",
      "Batch: 2 <--> Loss: 1.0733215808868408\n",
      "Batch: 3 <--> Loss: 1.0905319452285767\n",
      "Batch: 4 <--> Loss: 0.9593439102172852\n",
      "Batch: 5 <--> Loss: 0.9464313387870789\n",
      "Batch: 6 <--> Loss: 0.9665935635566711\n",
      "Epoc: 3\n",
      "Batch: 1 <--> Loss: 0.9121106863021851\n",
      "Batch: 2 <--> Loss: 0.8498024940490723\n",
      "Batch: 3 <--> Loss: 0.8412876129150391\n",
      "Batch: 4 <--> Loss: 0.8162268996238708\n",
      "Batch: 5 <--> Loss: 0.7940776944160461\n",
      "Batch: 6 <--> Loss: 0.7812292575836182\n",
      "Epoc: 4\n",
      "Batch: 1 <--> Loss: 0.7689026594161987\n",
      "Batch: 2 <--> Loss: 0.7372919321060181\n",
      "Batch: 3 <--> Loss: 0.7308430075645447\n",
      "Batch: 4 <--> Loss: 0.718188464641571\n",
      "Batch: 5 <--> Loss: 0.6985480785369873\n",
      "Batch: 6 <--> Loss: 0.6807054281234741\n",
      "Epoc: 5\n",
      "Batch: 1 <--> Loss: 0.6677761673927307\n",
      "Batch: 2 <--> Loss: 0.6416435241699219\n",
      "Batch: 3 <--> Loss: 0.6568002700805664\n",
      "Batch: 4 <--> Loss: 0.6071836352348328\n",
      "Batch: 5 <--> Loss: 0.594110906124115\n",
      "Batch: 6 <--> Loss: 0.5743710398674011\n",
      "Epoc: 6\n",
      "Batch: 1 <--> Loss: 0.5855072736740112\n",
      "Batch: 2 <--> Loss: 0.5517908334732056\n",
      "Batch: 3 <--> Loss: 0.5476542711257935\n",
      "Batch: 4 <--> Loss: 0.5350311398506165\n",
      "Batch: 5 <--> Loss: 0.5093010067939758\n",
      "Batch: 6 <--> Loss: 0.5013353824615479\n",
      "Epoc: 7\n",
      "Batch: 1 <--> Loss: 0.5103834867477417\n",
      "Batch: 2 <--> Loss: 0.49107471108436584\n",
      "Batch: 3 <--> Loss: 0.479024738073349\n",
      "Batch: 4 <--> Loss: 0.5214491486549377\n",
      "Batch: 5 <--> Loss: 0.4838184118270874\n",
      "Batch: 6 <--> Loss: 0.5536643266677856\n",
      "Epoc: 8\n",
      "Batch: 1 <--> Loss: 0.4651862382888794\n",
      "Batch: 2 <--> Loss: 0.4914478063583374\n",
      "Batch: 3 <--> Loss: 0.45094722509384155\n",
      "Batch: 4 <--> Loss: 0.46570006012916565\n",
      "Batch: 5 <--> Loss: 0.463172048330307\n",
      "Batch: 6 <--> Loss: 0.4370064437389374\n",
      "Epoc: 9\n",
      "Batch: 1 <--> Loss: 0.44748637080192566\n",
      "Batch: 2 <--> Loss: 0.4369761049747467\n",
      "Batch: 3 <--> Loss: 0.4312165081501007\n",
      "Batch: 4 <--> Loss: 0.43529582023620605\n",
      "Batch: 5 <--> Loss: 0.4061563313007355\n",
      "Batch: 6 <--> Loss: 0.4067164659500122\n",
      "Epoc: 10\n",
      "Batch: 1 <--> Loss: 0.396271675825119\n",
      "Batch: 2 <--> Loss: 0.3994911313056946\n",
      "Batch: 3 <--> Loss: 0.4021555185317993\n",
      "Batch: 4 <--> Loss: 0.3641056418418884\n",
      "Batch: 5 <--> Loss: 0.3748047649860382\n",
      "Batch: 6 <--> Loss: 0.37198495864868164\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net_C = Net_C()\n",
    "print(net_C)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net_C.parameters(), lr=0.001)\n",
    "\n",
    "loss_=[]\n",
    "def train(epoch):\n",
    "    #model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader,0):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net_C(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        #for _ , (data_val,target_val) in enumerate(val_loader,0)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss = loss.item()\n",
    "        loss_.append(running_loss)\n",
    "        print('Batch:',batch_idx+1,'<-->','Loss:',running_loss)\n",
    "        \n",
    "        #if(batch_idx !=0):    # print every 2000 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n",
    "            #running_loss = 0.0\n",
    "    \n",
    "\n",
    "\n",
    "# Training loop\n",
    "for i in range(epoc):\n",
    "    print('Epoc:',i+1)\n",
    "    train(i)\n",
    "    \n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_=np.asarray(loss_)\n",
    "\n",
    "epoch=np.linspace(0,len(loss_),len(loss_))\n",
    "\n",
    "plt.plot(epoch,loss_,label='Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Train_loss_Classification.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steingate/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 85 %\n",
      "torch.Size([6000])\n",
      "torch.Size([6000])\n",
      "torch.Size([12000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "d=[]\n",
    "d1=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net_C(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(predicted,predicted.shape)\n",
    "        d.append(predicted)\n",
    "        d1.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "#d=np.asarray(d)\n",
    "print(d[0].shape)\n",
    "print(d1[0].shape)\n",
    "y_pred=torch.cat((d[0],d[1]),0)\n",
    "y_test=torch.cat((d1[0],d1[1]),0)\n",
    "print(y_pred.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2c5e3c2952ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#y_pred=y_pred.detach().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cm_train.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#plt.subplots(122)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-2c5e3c2952ea>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(y_true, y_pred, classes, normalize, title, cmap)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Only use the labels that appear in the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "##### from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "class_names=['Star','Galaxy','QSO','QSO_BAL']\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,normalize=False,title=None,cmap=plt.cm.Blues):\n",
    "\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \"\"\"\n",
    "    #print(cm)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "#plt.subplots(121)\n",
    "#y_test=y_test.detach().numpy()\n",
    "#y_pred=y_pred.detach().numpy()\n",
    "#print(y_pred)\n",
    "plot_confusion_matrix(y_test, y_test, classes=class_names, title='Confusion matrix')\n",
    "plt.savefig('cm_train.png')\n",
    "#plt.subplots(122)\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, title='Confusion matrix')\n",
    "plt.savefig('cm_test.png')\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "p,r,f,s=precision_recall_fscore_support(y_test, y_pred, average=None)#,labels=['Star','Galaxy','QSO','QSO_BAL'])\n",
    "\n",
    "print('Support:','Star:',round(s[0],4),'| Galaxy:',round(s[1],4),'| QSO:',round(s[2],4),'| QSO_BAL:',round(s[3],4))\n",
    "print('Precision:','Star:',round(p[0],4),'| Galaxy:',round(p[1],4),'| QSO:',round(p[2],4),'| QSO_BAL:',round(p[3],4))\n",
    "print('Recall:','Star:',round(r[0],4),'| Galaxy:',round(r[1],4),'| QSO:',round(r[2],4),'| QSO_BAL:',round(r[3],4))\n",
    "print('F_score:','Star:',round(f[0],4),'| Galaxy:',round(f[1],4),'| QSO:',round(f[2],4),'| QSO_BAL:',round(f[3],4))\n",
    "\n",
    "end = time.time()\n",
    "print('Running time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "classes = ('Star', 'Galaxy', 'QSO', 'QSO_BAL')\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample=10000\n",
    "\n",
    "def Load_Files(file_1,file_2,N_sample,classification=True):\n",
    "    hdul = fits.open(file_1) # Open file 1 -- 'truth_DR12Q.fits'\n",
    "    info=hdul.info() # File info\n",
    "    columns=hdul[1].columns # File Columns \n",
    "    print('INFO:',info,'/n',columns)\n",
    "    data=hdul[1].data # Database of spectra with human-expert classifications \n",
    "\n",
    "    # Reading data from data_dr12.fits. This file had the spectra from data dr12. \n",
    "    hdul_2 = fits.open(file_2) # Open file 2 -- 'data_dr12.fits'\n",
    "    info2=hdul_2.info() # File info \n",
    "    columns2=hdul_2[1].columns # File Columns\n",
    "    print('INFO:',info2,'/n',columns2)\n",
    "    data2=hdul_2[1].data # Database of spectra\n",
    "    spectra=hdul_2[0].data # Spectrum of each object \n",
    "    \n",
    "    # Subset of PLATE parameters of both data\n",
    "    data_PLATE_1=data['PLATE']\n",
    "    data_PLATE_2=data2['PLATE']\n",
    "\n",
    "    # Subset of MJD parameters of both data\n",
    "    data_MJD_1=data['MJD']\n",
    "    data_MJD_2=data2['MJD']\n",
    "\n",
    "    # Subset of FIBERID parameters of both data\n",
    "    data_FIBERID_1=data['FIBERID']\n",
    "    data_FIBERID_2=data2['FIBERID']\n",
    "    data_ID_1=data['THING_ID']\n",
    "    data_ID_2=data2['TARGETID']\n",
    "    \n",
    "    # The column 'CLASS_PERSON' have a class identifier for each spectrum: STARS=1, GALAXY=4, QSO=3 and QSO_BAL=30.\n",
    "    C_P=data['CLASS_PERSON'] #Class Person column \n",
    "    STAR=C_P[C_P==1] # objects classified as stars\n",
    "    GALAXY=C_P[C_P==4] # objects classified as galaxies \n",
    "    QSO=C_P[C_P==3] # objects classified as QSO (Quasars)\n",
    "    QSO_BAL=C_P[C_P==30] # objects classified as QSO BAL (Quasars with Broad Absortions Lines)\n",
    "    N_C=C_P[C_P!=30]   \n",
    "    N_C=N_C[N_C!=3]\n",
    "    N_C=N_C[N_C!=1]\n",
    "    N_C=N_C[N_C!=4] # objects wrong classified\n",
    "    print('Star:',STAR.shape)\n",
    "    print('Galaxy:',GALAXY.shape)\n",
    "    print('QSO:',QSO.shape)\n",
    "    print('QSO BAL:',QSO_BAL.shape)\n",
    "    print('NN:',N_C.shape)\n",
    "    \n",
    "    # I create two DataFrame for Superset_DR12Q and data_dr12 with only three parameters\n",
    "    data1={'PLATE':data_PLATE_1,'MJD':data_MJD_1,'FIBERID':data_FIBERID_1,'ID':data_ID_1}\n",
    "    data1=pd.DataFrame(data=data1)\n",
    "\n",
    "    data2={'PLATE':data_PLATE_2,'MJD':data_MJD_2,'FIBERID':data_FIBERID_2,'ID':data_ID_2}\n",
    "    data2=pd.DataFrame(data=data2)\n",
    "\n",
    "    # I convert all objects in both set to string chain in orden to combine them as one new ID.\n",
    "    data1['PLATE']=data1['PLATE'].astype(str)\n",
    "    data1['MJD']=data1['MJD'].astype(str)\n",
    "    data1['FIBERID']=data1['FIBERID'].astype(str)\n",
    "    data1['PM'] = data1['MJD'].str.cat(data1['FIBERID'],sep=\"-\")\n",
    "    data1['NEWID'] = data1['PLATE'].str.cat(data1['PM'],sep=\"-\")\n",
    "    data_1=data1.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values\n",
    "\n",
    "    data2['PLATE']=data2['PLATE'].astype(str)\n",
    "    data2['MJD']=data2['MJD'].astype(str)\n",
    "    data2['FIBERID']=data2['FIBERID'].astype(str)\n",
    "    data2['PM'] = data2['MJD'].str.cat(data2['FIBERID'],sep=\"-\")\n",
    "    data2['NEWID'] = data2['PLATE'].str.cat(data2['PM'],sep=\"-\")\n",
    "    data_2=data2.drop(columns=['PLATE','MJD','FIBERID','ID','PM']).values # New set of database 2 with new ID's\n",
    "\n",
    "    # With the routine of numpy intersect1d, I find the intersections elements in both sets. This elements  \n",
    "    data_CO=np.array(np.intersect1d(data_1,data_2,return_indices=True))\n",
    "\n",
    "    data_CO_objects=data_CO[0] # The unique new ID of each element in both sets\n",
    "    data_CO_ind1=data_CO[1] # Indices of intersected elements from the original data 1 (Superset_DR12Q.fits) \n",
    "    data_CO_ind2=data_CO[2] # Indices of intersected elements form the original data 2 (data_dr12.fits)\n",
    "    print('I find',len(data_CO_objects),'objects with spectra from DR12')\n",
    "    #print(data_CO_ind1,data_CO_ind2)\n",
    "    indi={'ind1':data_CO_ind1,'ind2':data_CO_ind2}\n",
    "    ind=pd.DataFrame(data=indi,index=data_CO_ind1)\n",
    "\n",
    "    cp=np.array(data['CLASS_PERSON'],dtype=float)\n",
    "    z=np.array(data['Z_VI'],dtype=float)\n",
    "    zc=np.array(data['Z_CONF_PERSON'],dtype=float)\n",
    "    bal=np.array(data['BAL_FLAG_VI'],dtype=float)\n",
    "    bi=np.array(data['BI_CIV'],dtype=float)\n",
    "\n",
    "    d={'CLASS_PERSON':cp,'Z_VI':z,'Z_CONF_PERSON':zc,'BAL_FLAG_VI':bal,'BI_CIV':bi}\n",
    "    data_0=pd.DataFrame(data=d)#.values #super database\n",
    "    obj=data_0.loc[data_CO_ind1]\n",
    "\n",
    "    print(obj.shape)\n",
    "    # Sample of objects. I chosen 2500 object per class. \n",
    "    stars=obj.loc[obj['CLASS_PERSON']==1]\n",
    "    galaxies=obj.loc[obj['CLASS_PERSON']==4]\n",
    "    qsos=obj.loc[obj['CLASS_PERSON']==3]\n",
    "    qsos_bal=obj.loc[obj['CLASS_PERSON']==30]\n",
    "\n",
    "    sample_star=stars.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_galaxy=galaxies.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso=qsos.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "    sample_qso_bal=qsos_bal.sample(n=int(N_sample/4),weights='CLASS_PERSON', random_state=5)\n",
    "\n",
    "    sample_objects=pd.concat([sample_star,sample_galaxy,sample_qso,sample_qso_bal])\n",
    "\n",
    "    ind_star=np.array(sample_star.index)\n",
    "    ind_galaxy=np.array(sample_galaxy.index)\n",
    "    ind_qso=np.array(sample_qso.index)\n",
    "    ind_qso_bal=np.array(sample_qso_bal.index)\n",
    "\n",
    "    indi=np.concatenate((ind_star, ind_galaxy,ind_qso,ind_qso_bal), axis=None)\n",
    "    indi1=ind.loc[indi].values\n",
    "\n",
    "    spectra_=np.zeros((N_sample,886))\n",
    "    j=0\n",
    "    for i in indi:\n",
    "        k=indi1[j,1]\n",
    "        spectra_[j,:]=spectra[k,:]#np.log(abs(spectra[k,:443]))\n",
    "        j=j+1    \n",
    "    spectra_=pd.DataFrame(spectra_)\n",
    "    X=spectra_.values\n",
    "    \n",
    "    #Renormalize spectra\n",
    "    \n",
    "    mean_flx= np.ma.average(X[:,:443], weights=X[:,443:],axis=1)\n",
    "    ll=(X[:,:443]-mean_flx.reshape(-1,1))**2\n",
    "    aveflux=np.ma.average(ll, weights=X[:,443:],axis=1)\n",
    "    sflux = np.sqrt(aveflux)\n",
    "    X = (X[:,:443]-mean_flx.reshape(-1,1))/sflux.reshape(-1,1)\n",
    "\n",
    "    \n",
    "    if(classification!=True):\n",
    "        y=sample_objects['Z_VI']\n",
    "        y=np.array(y,dtype=float)\n",
    "        return X,y\n",
    "    else:  \n",
    "        y=sample_objects['CLASS_PERSON']\n",
    "        y=y.replace([1, 4, 3, 30], [0,1,2,3]).values\n",
    "        y=np.array(y,dtype=float)\n",
    "        return X,y\n",
    "\n",
    "\n",
    "def Loader(X,y,N_sample,epoc=10):\n",
    "    \n",
    "    batch_size=int(N_sample/epoc)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    for i in range(y_train.shape[0]):\n",
    "        xt=X_train[i,:].reshape(1,-1)\n",
    "        train_data.append([Variable(torch.tensor(xt, dtype=torch.float)), torch.tensor(y_train[i], dtype=torch.float)])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    test_data = []\n",
    "    for i in range(y_test.shape[0]):\n",
    "        xtst=X_test[i,:].reshape(1,-1)\n",
    "        test_data.append([Variable(torch.tensor(xtst, dtype=torch.float)), torch.tensor(y_test[i], dtype=torch.float)])\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    val_data = []\n",
    "    for i in range(y_val.shape[0]):\n",
    "        xv=X_val[i,:].reshape(1,-1)\n",
    "        val_data.append([Variable(torch.tensor(xv, dtype=torch.float)), torch.tensor(y_val[i], dtype=torch.float)])\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    print('INFO')\n",
    "    print('Train shape:',y_train.shape[0])\n",
    "    print('Val shape:',y_val.shape[0])\n",
    "    print('Test shape:',y_test.shape[0])\n",
    "    return train_loader,test_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "SpectraNET",
     "Regression"
    ]
   },
   "outputs": [],
   "source": [
    "class Net_R(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_R, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 100, 10,stride=2)\n",
    "        self.conv2 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv3 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.conv4 = nn.Conv1d(100, 100, 10,stride=2)\n",
    "        self.pool = nn.MaxPool1d(2, 1)\n",
    "        self.fc1 = nn.Linear(1800, 16)\n",
    "        #self.fc1 = nn.Linear(10300, 16)\n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "        self.fc3 = nn.Linear(4, 1)\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        ##x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = F.relu(self.fc1(x))     \n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=Load_Files('truth_DR12Q.fits','data_dr12.fits',N_sample,classification=False)\n",
    "train_loader,test_loader,val_loader=Loader(X,y,N_sample,epoc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "learning_rate=0.01\n",
    "log_interval=10\n",
    "epoc=10\n",
    "\n",
    "net_R = Net_R()\n",
    "print(net_R)\n",
    "\n",
    "optimizer = torch.optim.Adam(net_R.parameters(), lr=0.2) #for Rgrss\n",
    "loss_func = torch.nn.MSELoss()  \n",
    "loss_=[]\n",
    "def train(epoch):\n",
    "    #model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader,0):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net_R(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss = loss.item()\n",
    "        loss_.append(running_loss)\n",
    "        print('Batch:',batch_idx+1,'<-->','Loss:',running_loss)\n",
    "        #if(batch_idx !=0):    # print every 2000 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n",
    "            #running_loss = 0.0\n",
    "    \n",
    "\n",
    "\n",
    "# Training loop\n",
    "for i in range(epoc):\n",
    "    print('Epoc:',i+1)\n",
    "    train(i)\n",
    "    \n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "loss_=np.asarray(loss_)\n",
    "\n",
    "epoch=np.linspace(0,len(loss_),len(loss_))\n",
    "\n",
    "plt.plot(epoch,loss_,label='Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss - Regression')\n",
    "plt.legend()\n",
    "plt.savefig('Train_loss_Regression.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "d=[]\n",
    "d1=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net_R(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(predicted,predicted.shape)\n",
    "        d.append(predicted)\n",
    "        d1.append(labels)\n",
    "        #total += labels.size(0)\n",
    "        #correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "#print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "#d=np.asarray(d)\n",
    "print(d[0].shape)\n",
    "print(d1[0].shape)\n",
    "y_pred=torch.cat((d[0],d[1]),0)\n",
    "y_test=torch.cat((d1[0],d1[1]),0)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(y_pred,y_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_pred, y_test)\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
