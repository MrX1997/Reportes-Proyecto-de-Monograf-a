INFO: Epochs:50 -- Batch size:240 
Epoch: 0 -- LR: [0.001] 
train Loss: 0.14483190763741732 
val Loss: 0.4992741235718131 
Epoch: 1 -- LR: [0.00010000000000000002] 
train Loss: 0.09627944950014353 
val Loss: 0.34858475178480147 
Epoch: 2 -- LR: [1.0000000000000003e-05] 
train Loss: 0.09379898473620414 
val Loss: 0.34017194788903 
Epoch: 3 -- LR: [1.0000000000000002e-06] 
train Loss: 0.09400668762624263 
val Loss: 0.34186319321393965 
Epoch: 4 -- LR: [1.0000000000000002e-07] 
train Loss: 0.09375501845031976 
val Loss: 0.3409005742892623 
Epoch: 5 -- LR: [1.0000000000000004e-08] 
train Loss: 0.09256107483059167 
val Loss: 0.33759304918348787 
Epoch: 6 -- LR: [1.0000000000000005e-09] 
train Loss: 0.09219914719462395 
val Loss: 0.3374908075109124 
Epoch: 7 -- LR: [1.0000000000000006e-10] 
train Loss: 0.09250051274895668 
val Loss: 0.33739937249571084 
Epoch: 8 -- LR: [1.0000000000000004e-11] 
train Loss: 0.092966202609241 
val Loss: 0.33911120671778916 
Epoch: 9 -- LR: [1.0000000000000006e-12] 
train Loss: 0.09279935389757156 
val Loss: 0.3371530714631081 
Epoch: 10 -- LR: [1.0000000000000007e-13] 
train Loss: 0.09390016749501229 
val Loss: 0.34063576109707355 
Epoch: 11 -- LR: [1.0000000000000006e-14] 
train Loss: 0.09294032912701368 
val Loss: 0.33794314324855806 
Epoch: 12 -- LR: [1.0000000000000007e-15] 
train Loss: 0.092926076464355 
val Loss: 0.3385573438182473 
Epoch: 13 -- LR: [1.0000000000000008e-16] 
train Loss: 0.09212277445942163 
val Loss: 0.33645396165549757 
Epoch: 14 -- LR: [1.0000000000000008e-17] 
train Loss: 0.09296503715217114 
val Loss: 0.3386697927862406 
Epoch: 15 -- LR: [1.0000000000000008e-18] 
train Loss: 0.09423908188939095 
val Loss: 0.34228873811662197 
Epoch: 16 -- LR: [1.000000000000001e-19] 
train Loss: 0.09302499156445265 
val Loss: 0.3393671795725822 
Epoch: 17 -- LR: [1.000000000000001e-20] 
train Loss: 0.09336296994239092 
val Loss: 0.34001282896846535 
Epoch: 18 -- LR: [1.000000000000001e-21] 
train Loss: 0.09352881956845521 
val Loss: 0.34003158047795295 
Epoch: 19 -- LR: [1.0000000000000012e-22] 
train Loss: 0.09310180243104696 
val Loss: 0.3382340772822499 
Epoch: 20 -- LR: [1.0000000000000013e-23] 
train Loss: 0.09302876479923725 
val Loss: 0.338271610699594 
Epoch: 21 -- LR: [1.0000000000000012e-24] 
train Loss: 0.09318122487515211 
val Loss: 0.3388786134496331 
Epoch: 22 -- LR: [1.0000000000000013e-25] 
train Loss: 0.09285999219864607 
val Loss: 0.33937878321856263 
Epoch: 23 -- LR: [1.0000000000000015e-26] 
train Loss: 0.09369603846222162 
val Loss: 0.34010573495179414 
Epoch: 24 -- LR: [1.0000000000000015e-27] 
train Loss: 0.09365005902945996 
val Loss: 0.34157658498734234 
Epoch: 25 -- LR: [1.0000000000000015e-28] 
train Loss: 0.09380862254649401 
val Loss: 0.34169688865542414 
Epoch: 26 -- LR: [1.0000000000000015e-29] 
train Loss: 0.09329537827521563 
val Loss: 0.3408478241041303 
Epoch: 27 -- LR: [1.0000000000000015e-30] 
train Loss: 0.09391766671091319 
val Loss: 0.3413016068190336 
Epoch: 28 -- LR: [1.0000000000000016e-31] 
train Loss: 0.09289706233888864 
val Loss: 0.3385731537640095 
Epoch: 29 -- LR: [1.0000000000000017e-32] 
train Loss: 0.09289881724864245 
val Loss: 0.3380744858458638 
Epoch: 30 -- LR: [1.0000000000000016e-33] 
train Loss: 0.0929887829348445 
val Loss: 0.33860960736870765 
Epoch: 31 -- LR: [1.0000000000000019e-34] 
train Loss: 0.09351864609867334 
val Loss: 0.3387955516949296 
Epoch: 32 -- LR: [1.0000000000000017e-35] 
train Loss: 0.09319425102323294 
val Loss: 0.3399940039590001 
Epoch: 33 -- LR: [1.000000000000002e-36] 
train Loss: 0.09369864020496607 
val Loss: 0.341190857924521 
Epoch: 34 -- LR: [1.000000000000002e-37] 
train Loss: 0.09315785925835371 
val Loss: 0.3399533727392554 
Epoch: 35 -- LR: [1.0000000000000019e-38] 
train Loss: 0.09301844738423824 
val Loss: 0.3388683454692364 
Epoch: 36 -- LR: [1.0000000000000022e-39] 
train Loss: 0.09335007134824991 
val Loss: 0.3403042399138212 
Epoch: 37 -- LR: [1.0000000000000022e-40] 
train Loss: 0.09303300619125367 
val Loss: 0.3405120373889804 
Epoch: 38 -- LR: [1.0000000000000022e-41] 
train Loss: 0.09334907107055188 
val Loss: 0.34076519139111044 
Epoch: 39 -- LR: [1.0000000000000023e-42] 
train Loss: 0.0929576787725091 
val Loss: 0.33763076066970826 
Epoch: 40 -- LR: [1.0000000000000023e-43] 
train Loss: 0.09294019248336553 
val Loss: 0.3385079126432538 
Epoch: 41 -- LR: [1.0000000000000023e-44] 
train Loss: 0.09323516923934222 
val Loss: 0.338468769416213 
Epoch: 42 -- LR: [1.0000000000000025e-45] 
train Loss: 0.092846538759768 
val Loss: 0.3393485265597701 
Epoch: 43 -- LR: [1.0000000000000026e-46] 
train Loss: 0.09294130768626928 
val Loss: 0.3397934831678867 
Epoch: 44 -- LR: [1.0000000000000025e-47] 
train Loss: 0.09294496815651655 
val Loss: 0.33984718564897776 
Epoch: 45 -- LR: [1.0000000000000026e-48] 
train Loss: 0.09297379627823829 
val Loss: 0.33766567081212995 
Epoch: 46 -- LR: [1.0000000000000026e-49] 
train Loss: 0.09273588631302118 
val Loss: 0.33787448678165677 
Epoch: 47 -- LR: [1.0000000000000027e-50] 
train Loss: 0.09272272258996964 
val Loss: 0.3385951980575919 
Epoch: 48 -- LR: [1.0000000000000028e-51] 
train Loss: 0.09342541497200728 
val Loss: 0.3390915036946535 
Epoch: 49 -- LR: [1.0000000000000028e-52] 
train Loss: 0.09312559828162194 
val Loss: 0.33905530456453564 
MSE: 0.06095501780509949 
MAE: 0.21498234570026398 
R2: -33.1590000640307 
Time: 12886.372806310654 
y pred: [0.08983748 0.1417942  0.15506813 ... 0.08849221 0.14846423 0.1815249 ]
y test: [0.4265528  0.42375776 0.34440994 ... 0.3484472  0.2940994  0.35885093]
